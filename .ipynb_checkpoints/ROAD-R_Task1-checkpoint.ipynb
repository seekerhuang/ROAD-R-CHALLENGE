{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "To train the model, provide the following positional arguments:\n",
    "   - `TASK`: set to 1, to use only 3 out of 15 videos from the training partition train_1.\n",
    "   - `DATA_ROOT`: path to a directory in which `road` can be found, containing `road_test_v1.0.json`, `road_trainval_v1.0.json`, and directories `rgb-images` and `videos`.\n",
    "   - `SAVE_ROOT`: path to a directory in which the experiments (e.g. checkpoints, training logs) will be saved.\n",
    "   - `MODEL_PATH`: path to the directory containing the weights for the chosen backbone (e.g. `resnet50RCGRU.pth`).\n",
    "\n",
    "The remaining arguments are optional and include `MODEL_TYPE`, `BATCH_SIZE`, `MAX_EPOCHS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpretrain/v1.0/dinov2/vit-giant-p14_dinov2-pre_3rdparty_20230426-2934a630.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.mask_token\n",
      "\n",
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "Create:  /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x/\n",
      "[INFO: main.py:  268]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  401]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  401]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  401]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 4033 out of 4734 in 2014-06-25-16-45-34_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 473\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5597 out of 6001 in 2014-07-14-14-49-50_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5345 out of 6000 in 2014-07-14-15-42-55_stereo_centre_03\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5801 out of 6001 in 2014-08-08-13-15-11_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 1168 out of 1168 in 2014-08-11-10-59-18_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 116\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5134 out of 6000 in 2014-11-14-16-34-33_stereo_centre_06\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5724 out of 6000 in 2014-11-18-13-20-12_stereo_centre_05\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 4804 out of 6001 in 2014-11-21-16-07-03_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5710 out of 6001 in 2014-12-09-13-21-02_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5611 out of 6000 in 2015-02-03-08-45-10_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5473 out of 6000 in 2015-02-03-19-43-11_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5431 out of 6000 in 2015-02-06-13-57-16_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5316 out of 6000 in 2015-02-13-09-16-26_stereo_centre_05\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5859 out of 6000 in 2015-02-24-12-32-19_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5133 out of 6001 in 2015-03-03-11-31-36_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 599\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  292]: Done Loading Train Dataset\n",
      "[INFO: utils_ssl.py:   28]: Saved ulb indices at ulb_split_indices/ulb_indices_ssl-unlbl-prop-0.0-10-23-09-28-54.pkl\n",
      "[INFO: datasets.py:  401]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  401]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  401]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 63\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 63\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 63\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  323]: Done Loading Dataset Validation Dataset\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Cell anchors\n",
      " BufferList()\n",
      "kernel_size 5\n",
      "kernel_size 5\n",
      "kernel_size 7\n",
      "[INFO: main.py:  342]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  342]: ARCH: resnet50\n",
      "[INFO: main.py:  342]: BATCH_SIZE: 8\n",
      "[INFO: main.py:  342]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  342]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  342]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  342]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  342]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  342]: DATASET: road\n",
      "[INFO: main.py:  342]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  342]: DATETIME_NOW: 2023-10-23 09:28:54.438990\n",
      "[INFO: main.py:  342]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  342]: EVAL_EPOCHS: [150]\n",
      "[INFO: main.py:  342]: EXP_NAME: \n",
      "[INFO: main.py:  342]: FBN: True\n",
      "[INFO: main.py:  342]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  342]: GAMMA: 0.1\n",
      "[INFO: main.py:  342]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  342]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  342]: GEN_TOPK: 30\n",
      "[INFO: main.py:  342]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  342]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  342]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  342]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  342]: LOG_START: 10\n",
      "[INFO: main.py:  342]: LOG_STEP: 10\n",
      "[INFO: main.py:  342]: LR: 6e-05\n",
      "[INFO: main.py:  342]: MAN_SEED: 3407\n",
      "[INFO: main.py:  342]: MAX_EPOCHS: 25\n",
      "[INFO: main.py:  342]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  342]: MAX_SIZE: 691\n",
      "[INFO: main.py:  342]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  342]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  342]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  342]: MIN_SIZE: 512\n",
      "[INFO: main.py:  342]: MODE: train\n",
      "[INFO: main.py:  342]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  342]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  342]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  342]: MULTI_GPUS: True\n",
      "[INFO: main.py:  342]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  342]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  342]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  342]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  342]: OPTIM: ADAMW\n",
      "[INFO: main.py:  342]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  342]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  342]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  342]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  342]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  342]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  342]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  342]: RESUME: 0\n",
      "[INFO: main.py:  342]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x/\n",
      "[INFO: main.py:  342]: SEQ_LEN: 12\n",
      "[INFO: main.py:  342]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  342]: SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: TASK: 1\n",
      "[INFO: main.py:  342]: TENSORBOARD: 1\n",
      "[INFO: main.py:  342]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  342]: TEST_SEQ_LEN: 12\n",
      "[INFO: main.py:  342]: TEST_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: TOPK: 30\n",
      "[INFO: main.py:  342]: TRAIN_SUBSETS: ['train_1']\n",
      "[INFO: main.py:  342]: TRIM_METHOD: none\n",
      "[INFO: main.py:  342]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  342]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  342]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  342]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  342]: VAL_STEP: 1\n",
      "[INFO: main.py:  342]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  342]: WEIGHT_DECAY: 0.035\n",
      "[INFO: main.py:  342]: agentness_th: 0.125\n",
      "[INFO: main.py:  342]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  342]: ar: 9\n",
      "[INFO: main.py:  342]: exp_name: resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x\n",
      "[INFO: main.py:  342]: flow_path: /root/autodl-tmp/unimatch-master/output/road_data_flow\n",
      "[INFO: main.py:  342]: head_size: 256\n",
      "[INFO: main.py:  342]: hostname: autodl-container-5ce511b6ae-ee4ae13a\n",
      "[INFO: main.py:  342]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  342]: labelled_videos: ['2014-07-14-14-49-50_stereo_centre_01', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-24-12-32-19_stereo_centre_04']\n",
      "[INFO: main.py:  342]: log_dir: logs/resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x/\n",
      "[INFO: main.py:  342]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  342]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  342]: model_init: kinetics\n",
      "[INFO: main.py:  342]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  342]: model_subtype: RCGRU\n",
      "[INFO: main.py:  342]: modeldino: True\n",
      "[INFO: main.py:  342]: modelswin: False\n",
      "[INFO: main.py:  342]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  342]: num_classes: 42\n",
      "[INFO: main.py:  342]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  342]: num_label_types: 4\n",
      "[INFO: main.py:  342]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  342]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\n",
      "[INFO: main.py:  342]: pretrained_model_pathfpn: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/yolox_l.pth\n",
      "[INFO: main.py:  342]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  342]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  342]: user: root\n",
      "backbone.backbone.tconv.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.deconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.flowbackbone.norm3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.flowbackbone.norm3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime1.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime1.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime2.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime2.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.catconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv1.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.lateral_conv0.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.reduce_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead4.conv.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.bias is trained at the rate of 0.00012\n",
      "reg_heads.2.weight is trained at the rate of 6e-05\n",
      "reg_heads.2.bias is trained at the rate of 0.00012\n",
      "reg_heads.4.weight is trained at the rate of 6e-05\n",
      "reg_heads.4.bias is trained at the rate of 0.00012\n",
      "reg_heads.6.weight is trained at the rate of 6e-05\n",
      "reg_heads.6.bias is trained at the rate of 0.00012\n",
      "cls_heads.0.weight is trained at the rate of 6e-05\n",
      "cls_heads.0.bias is trained at the rate of 0.00012\n",
      "cls_heads.2.weight is trained at the rate of 6e-05\n",
      "cls_heads.2.bias is trained at the rate of 0.00012\n",
      "cls_heads.4.weight is trained at the rate of 6e-05\n",
      "cls_heads.4.bias is trained at the rate of 0.00012\n",
      "cls_heads.6.weight is trained at the rate of 6e-05\n",
      "cls_heads.6.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearcls.norm1.weight is trained at the rate of 6e-05\n",
      "linearcls.norm1.bias is trained at the rate of 0.00012\n",
      "linearcls.norm2.weight is trained at the rate of 6e-05\n",
      "linearcls.norm2.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup1.norm1.weight is trained at the rate of 6e-05\n",
      "linearup1.norm1.bias is trained at the rate of 0.00012\n",
      "linearup1.norm2.weight is trained at the rate of 6e-05\n",
      "linearup1.norm2.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup2.norm1.weight is trained at the rate of 6e-05\n",
      "linearup2.norm1.bias is trained at the rate of 0.00012\n",
      "linearup2.norm2.weight is trained at the rate of 6e-05\n",
      "linearup2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm2.bias is trained at the rate of 0.00012\n",
      "[INFO: train.py:  155]: Created tensorboard log dir logs/resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x//log-lo_tboard-train-10-23-09-28-54_logic-Lukasiewicz_req-weight-8.0\n",
      "(257, 257, 1, 3, 3)\n",
      "avg (256, 1, 3, 3)\n",
      "(257, 257, 1, 3, 3)\n",
      "(257, 257, 1, 3, 3)\n",
      "avg (256, 1, 3, 3)\n",
      "(257, 257, 1, 3, 3)\n",
      "(257, 257, 1, 3, 3)\n",
      "avg (256, 1, 3, 3)\n",
      "(257, 257, 1, 3, 3)\n",
      "cls_heads.0.weight torch.Size([257, 257, 1, 3, 3])\n",
      "cls_heads.0.bias torch.Size([257])\n",
      "cls_heads.2.weight torch.Size([257, 257, 1, 3, 3])\n",
      "cls_heads.2.bias torch.Size([257])\n",
      "cls_heads.4.weight torch.Size([257, 257, 1, 3, 3])\n",
      "cls_heads.4.bias torch.Size([257])\n",
      "missing\n",
      "['anchors.cell_anchors.0', 'anchors.cell_anchors.1', 'anchors.cell_anchors.2', 'anchors.cell_anchors.3', 'anchors.cell_anchors.4', 'backbone.backbone.rgbbackbone.dinobackbone.cls_token', 'backbone.backbone.rgbbackbone.dinobackbone.pos_embed', 'backbone.backbone.rgbbackbone.dinobackbone.patch_embed.projection.weight', 'backbone.backbone.rgbbackbone.dinobackbone.patch_embed.projection.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.0.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.1.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.2.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.3.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.4.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.5.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.6.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.7.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.8.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.9.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.10.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.11.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.12.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.13.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.14.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.15.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.16.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.17.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.18.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.19.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.20.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.21.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.22.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.23.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.24.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.25.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.26.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.27.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.28.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.29.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.30.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.31.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.32.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.33.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.34.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.35.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.36.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.37.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.38.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ln1.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.attn.qkv.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.attn.qkv.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.attn.proj.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.attn.proj.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.attn.gamma1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ln2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ln2.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ffn.w12.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ffn.w12.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ffn.w3.weight', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ffn.w3.bias', 'backbone.backbone.rgbbackbone.dinobackbone.layers.39.ffn.gamma2.weight', 'backbone.backbone.rgbbackbone.dinobackbone.ln1.weight', 'backbone.backbone.rgbbackbone.dinobackbone.ln1.bias', 'backbone.backbone.tconv.tconv1.conv.weight', 'backbone.backbone.tconv.tconv1.conv.bias', 'backbone.backbone.tconv.tconv2.conv.weight', 'backbone.backbone.tconv.tconv2.conv.bias', 'backbone.backbone.tconv.tconv3.conv.weight', 'backbone.backbone.tconv.tconv3.conv.bias', 'backbone.backbone.tconv.tavg.conv.weight', 'backbone.backbone.tconv.norm.weight', 'backbone.backbone.tconv.norm.bias', 'backbone.backbone.tconv_1.tconv1.conv.weight', 'backbone.backbone.tconv_1.tconv1.conv.bias', 'backbone.backbone.tconv_1.tconv2.conv.weight', 'backbone.backbone.tconv_1.tconv2.conv.bias', 'backbone.backbone.tconv_1.tconv3.conv.weight', 'backbone.backbone.tconv_1.tconv3.conv.bias', 'backbone.backbone.tconv_1.tavg.conv.weight', 'backbone.backbone.tconv_1.norm.weight', 'backbone.backbone.tconv_1.norm.bias', 'backbone.backbone.tconv_2.tconv1.conv.weight', 'backbone.backbone.tconv_2.tconv1.conv.bias', 'backbone.backbone.tconv_2.tconv2.conv.weight', 'backbone.backbone.tconv_2.tconv2.conv.bias', 'backbone.backbone.tconv_2.tconv3.conv.weight', 'backbone.backbone.tconv_2.tconv3.conv.bias', 'backbone.backbone.tconv_2.tavg.conv.weight', 'backbone.backbone.tconv_2.norm.weight', 'backbone.backbone.tconv_2.norm.bias', 'backbone.backbone.tconv_3.tconv1.conv.weight', 'backbone.backbone.tconv_3.tconv1.conv.bias', 'backbone.backbone.tconv_3.tconv2.conv.weight', 'backbone.backbone.tconv_3.tconv2.conv.bias', 'backbone.backbone.tconv_3.tconv3.conv.weight', 'backbone.backbone.tconv_3.tconv3.conv.bias', 'backbone.backbone.tconv_3.tavg.conv.weight', 'backbone.backbone.tconv_3.norm.weight', 'backbone.backbone.tconv_3.norm.bias', 'backbone.backbone.conv2.conv.weight', 'backbone.backbone.conv2.ln.weight', 'backbone.backbone.conv2.ln.bias', 'backbone.backbone.deconv3.conv.weight', 'backbone.backbone.deconv3.ln.weight', 'backbone.backbone.deconv3.ln.bias', 'backbone.backbone.uptime1.weight', 'backbone.backbone.uptime1.bias', 'backbone.backbone.uptime2.weight', 'backbone.backbone.uptime2.bias', 'backbone.backbone.uptime3.weight', 'backbone.backbone.uptime3.bias', 'backbone.backbone.catconv1.conv.weight', 'backbone.backbone.catconv1.eca.conveca.weight', 'backbone.backbone.catconv2.conv.weight', 'backbone.backbone.catconv2.eca.conveca.weight', 'backbone.backbone.catconv3.conv.weight', 'backbone.backbone.catconv3.eca.conveca.weight', 'backbone.upcovhead1.conv.weight', 'backbone.upcovhead2.conv.weight', 'backbone.upcovhead3.conv.weight', 'backbone.upcovhead4.conv.weight', 'cls_heads.6.weight', 'cls_heads.6.bias', 'linearcls.linearcls1.weight', 'linearcls.linearcls1.bias', 'linearcls.linearcls2.weight', 'linearcls.linearcls2.bias', 'linearcls.norm1.weight', 'linearcls.norm1.bias', 'linearcls.norm2.weight', 'linearcls.norm2.bias', 'linearup1.linearcls1.weight', 'linearup1.linearcls1.bias', 'linearup1.linearcls2.weight', 'linearup1.linearcls2.bias', 'linearup1.norm1.weight', 'linearup1.norm1.bias', 'linearup1.norm2.weight', 'linearup1.norm2.bias', 'linearup2.linearcls1.weight', 'linearup2.linearcls1.bias', 'linearup2.linearcls2.weight', 'linearup2.linearcls2.bias', 'linearup2.norm1.weight', 'linearup2.norm1.bias', 'linearup2.norm2.weight', 'linearup2.norm2.bias', 'lineardown1.linearcls1.weight', 'lineardown1.linearcls1.bias', 'lineardown1.linearcls2.weight', 'lineardown1.linearcls2.bias', 'lineardown1.norm1.weight', 'lineardown1.norm1.bias', 'lineardown1.norm2.weight', 'lineardown1.norm2.bias', 'lineardown2.linearcls1.weight', 'lineardown2.linearcls1.bias', 'lineardown2.linearcls2.weight', 'lineardown2.linearcls2.bias', 'lineardown2.norm1.weight', 'lineardown2.norm1.bias', 'lineardown2.norm2.weight', 'lineardown2.norm2.bias', 'lineardown3.linearcls1.weight', 'lineardown3.linearcls1.bias', 'lineardown3.linearcls2.weight', 'lineardown3.linearcls2.bias', 'lineardown3.norm1.weight', 'lineardown3.norm1.bias', 'lineardown3.norm2.weight', 'lineardown3.norm2.bias']\n",
      "unexpcted\n",
      "[]\n",
      "[INFO: train.py:  375]: Load pretrained model /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: train.py:  377]: \n",
      "Lets do dataparallel\n",
      "\n",
      "[INFO: train.py:  381]: DataParallel(\n",
      "  (module): DinoRetinaNet(\n",
      "    (anchors): anchorBox(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (backbone): YOLOPAFPN3DDINO(\n",
      "      (backbone): TSVideoSwinBackbone(\n",
      "        (rgbbackbone): viedoDINORGB(\n",
      "          (dinobackbone): VisionTransformer(\n",
      "            (patch_embed): PatchEmbed(\n",
      "              (adaptive_padding): AdaptivePadding()\n",
      "              (projection): Conv2d(3, 1536, kernel_size=(14, 14), stride=(14, 14))\n",
      "            )\n",
      "            (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
      "            (layers): ModuleList(\n",
      "              (0-39): 40 x TransformerEncoderLayer(\n",
      "                (ln1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "                (attn): MultiheadAttention(\n",
      "                  (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                  (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (out_drop): DropPath()\n",
      "                  (gamma1): LayerScale()\n",
      "                )\n",
      "                (ln2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "                (ffn): SwiGLUFFNFused(\n",
      "                  (w12): Linear(in_features=1536, out_features=8192, bias=True)\n",
      "                  (norm): Identity()\n",
      "                  (w3): Linear(in_features=4096, out_features=1536, bias=True)\n",
      "                  (gamma2): LayerScale()\n",
      "                  (dropout_layer): Identity()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (pre_norm): Identity()\n",
      "            (ln1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (tconv): TimeGlobalMultiScaleBlock(\n",
      "          (tconv1): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1536, 1536, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          )\n",
      "          (tconv2): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1536, 1536, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "          )\n",
      "          (tconv3): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1536, 1536, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "          )\n",
      "          (tavg): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(4608, 1536, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (tconv_1): TimeGlobalMultiScaleBlock(\n",
      "          (tconv1): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          )\n",
      "          (tconv2): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "          )\n",
      "          (tconv3): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "          )\n",
      "          (tavg): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (tconv_2): TimeGlobalMultiScaleBlock(\n",
      "          (tconv1): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          )\n",
      "          (tconv2): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(512, 512, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "          )\n",
      "          (tconv3): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(512, 512, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "          )\n",
      "          (tavg): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1536, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (tconv_3): TimeGlobalMultiScaleBlock(\n",
      "          (tconv1): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1024, 1024, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          )\n",
      "          (tconv2): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1024, 1024, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "          )\n",
      "          (tconv3): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(1024, 1024, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "          )\n",
      "          (tavg): BaseOnlyConv3D(\n",
      "            (conv): Conv3d(3072, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (conv2): BaseConv3DDINO(\n",
      "          (conv): Conv3d(1536, 768, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (deconv3): BaseTransConv3DDINO(\n",
      "          (conv): ConvTranspose3d(1536, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (act): GELU(approximate='none')\n",
      "        )\n",
      "        (flowbackbone): viedoswinFlow(\n",
      "          (patch_embed): PatchEmbed3D(\n",
      "            (proj): Conv3d(3, 192, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
      "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "          (swinaclayer1): BasicLayer(\n",
      "            (blocks): ModuleList(\n",
      "              (0): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.017)\n",
      "                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (downsample): PatchMerging(\n",
      "              (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (swinaclayer2): BasicLayer(\n",
      "            (blocks): ModuleList(\n",
      "              (0): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.035)\n",
      "                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.052)\n",
      "                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (downsample): PatchMerging(\n",
      "              (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (swinaclayer3): BasicLayer(\n",
      "            (blocks): ModuleList(\n",
      "              (0): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.070)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.087)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.104)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.122)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.139)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.157)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.174)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.191)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.209)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.226)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.243)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.261)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (12): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.278)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (13): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.296)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (14): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.313)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (15): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.330)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (16): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.348)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (17): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.365)\n",
      "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (downsample): PatchMerging(\n",
      "              (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "              (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (swinaclayer4): BasicLayer(\n",
      "            (blocks): ModuleList(\n",
      "              (0): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.383)\n",
      "                (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): SwinTransformerBlock3D(\n",
      "                (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention3D(\n",
      "                  (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.400)\n",
      "                (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                  (drop): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (uptime1): ConvTranspose3d(384, 384, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "        (uptime2): ConvTranspose3d(768, 768, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "        (uptime3): ConvTranspose3d(1536, 1536, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "        (catconv1): TSAttBlock(\n",
      "          (conv): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (eca): ChannAT(\n",
      "            (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "            (conveca): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (catconv2): TSAttBlock(\n",
      "          (conv): Conv3d(1536, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (eca): ChannAT(\n",
      "            (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "            (conveca): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (catconv3): TSAttBlock(\n",
      "          (conv): Conv3d(3072, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (eca): ChannAT(\n",
      "            (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "            (conveca): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='nearest')\n",
      "      (lateral_conv0): BaseConv3D(\n",
      "        (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (C3_p4): CSPLayer3DDINO(\n",
      "        (conv1): BaseConv3D(\n",
      "          (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): BaseConv3D(\n",
      "          (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv3): BaseConv3D(\n",
      "          (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (reduce_conv1): BaseConv3D(\n",
      "        (conv): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (C3_p3): CSPLayer3D(\n",
      "        (conv1): BaseConv3D(\n",
      "          (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): BaseConv3D(\n",
      "          (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv3): BaseConv3D(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bu_conv2): BaseConv3D(\n",
      "        (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (C3_n3): CSPLayer3D(\n",
      "        (conv1): BaseConv3D(\n",
      "          (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): BaseConv3D(\n",
      "          (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv3): BaseConv3D(\n",
      "          (conv): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck3D(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bu_conv1): BaseConv3D(\n",
      "        (conv): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (C3_n4): CSPLayer3DDINO(\n",
      "        (conv1): BaseConv3D(\n",
      "          (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): BaseConv3D(\n",
      "          (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv3): BaseConv3D(\n",
      "          (conv): Conv3d(1024, 1024, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck3DDINO(\n",
      "            (conv1): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv2): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upcovhead1): BaseOnlyConv3D(\n",
      "        (conv): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      )\n",
      "      (upcovhead2): BaseOnlyConv3D(\n",
      "        (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      )\n",
      "      (upcovhead3): BaseOnlyConv3D(\n",
      "        (conv): Conv3d(1024, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (upcovhead4): BaseOnlyConv3D(\n",
      "        (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (reg_heads): Sequential(\n",
      "      (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (5): GELU(approximate='none')\n",
      "      (6): Conv3d(256, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    )\n",
      "    (cls_heads): Sequential(\n",
      "      (0): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "      (5): GELU(approximate='none')\n",
      "      (6): Conv3d(257, 378, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    )\n",
      "    (linearcls): dinov2linear(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (linearup1): dinov2linearFix(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=5632, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=5632, out_features=5632, bias=True)\n",
      "      (norm1): LayerNorm((5632,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((5632,), eps=1e-05, elementwise_affine=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "    )\n",
      "    (linearup2): dinov2linearFix(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=1408, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (norm1): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "    )\n",
      "    (lineardown1): dinov2linearFix(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=352, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=352, out_features=352, bias=True)\n",
      "      (norm1): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "    )\n",
      "    (lineardown2): dinov2linearFix(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=88, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=88, out_features=88, bias=True)\n",
      "      (norm1): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "    )\n",
      "    (lineardown3): dinov2linearFix(\n",
      "      (linearcls1): Linear(in_features=1536, out_features=24, bias=True)\n",
      "      (liclsact1): GELU(approximate='none')\n",
      "      (linearcls2): Linear(in_features=24, out_features=24, bias=True)\n",
      "      (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "      (liclsact2): GELU(approximate='none')\n",
      "    )\n",
      "    (criterion): FocalLoss()\n",
      "  )\n",
      ")\n",
      "[INFO: train.py:  382]: \n",
      "\n",
      "Solver configs are as follow \n",
      "\n",
      "\n",
      "backbone.backbone.tconv.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.deconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.flowbackbone.norm3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.flowbackbone.norm3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime1.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime1.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime2.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime2.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.catconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv1.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.lateral_conv0.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.reduce_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead4.conv.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.bias is trained at the rate of 0.00012\n",
      "reg_heads.2.weight is trained at the rate of 6e-05\n",
      "reg_heads.2.bias is trained at the rate of 0.00012\n",
      "reg_heads.4.weight is trained at the rate of 6e-05\n",
      "reg_heads.4.bias is trained at the rate of 0.00012\n",
      "reg_heads.6.weight is trained at the rate of 6e-05\n",
      "reg_heads.6.bias is trained at the rate of 0.00012\n",
      "cls_heads.0.weight is trained at the rate of 6e-05\n",
      "cls_heads.0.bias is trained at the rate of 0.00012\n",
      "cls_heads.2.weight is trained at the rate of 6e-05\n",
      "cls_heads.2.bias is trained at the rate of 0.00012\n",
      "cls_heads.4.weight is trained at the rate of 6e-05\n",
      "cls_heads.4.bias is trained at the rate of 0.00012\n",
      "cls_heads.6.weight is trained at the rate of 6e-05\n",
      "cls_heads.6.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearcls.norm1.weight is trained at the rate of 6e-05\n",
      "linearcls.norm1.bias is trained at the rate of 0.00012\n",
      "linearcls.norm2.weight is trained at the rate of 6e-05\n",
      "linearcls.norm2.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup1.norm1.weight is trained at the rate of 6e-05\n",
      "linearup1.norm1.bias is trained at the rate of 0.00012\n",
      "linearup1.norm2.weight is trained at the rate of 6e-05\n",
      "linearup1.norm2.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup2.norm1.weight is trained at the rate of 6e-05\n",
      "linearup2.norm1.bias is trained at the rate of 0.00012\n",
      "linearup2.norm2.weight is trained at the rate of 6e-05\n",
      "linearup2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm2.bias is trained at the rate of 0.00012\n",
      "optimizer is ADAMW\n",
      "Done solver configs\n",
      "\n",
      "\n",
      "[INFO: train.py:  384]: EXPERIMENT NAME:: resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x\n",
      "[INFO: train.py:  385]: Training FPN with resnet50 + RCGRU as backbone \n",
      "LR at epoch 1 is [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06]\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/road/\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"F:/gta5/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "pretrained_model_path=\"F:\\\\gta5\\\\swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\"\n",
    "pretrained_model_path2=\"F:\\\\A-ROAD-CHALL\\\\weights\\\\weights_task1\\\\pretrained_weights_task1.pth\"\n",
    "TASK=1\n",
    "SAVE_ROOT=\"F:/A-ROAD-CHALL/new_video_test/SAVE/\"\n",
    "EXP_ID=\"task1\"\n",
    "\n",
    "!  python main.py --TASK=1 --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE/\" --MODE=\"train\" --LOGIC=\"Lukasiewicz\" --VAL_STEP=1 --LR=6e-5 --MAX_EPOCHS=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming the training\n",
    "To resume the training of a model, provide the path to the directory containing the checkpoint from which the experiment should be resumed in the `EXP_NAME` argument.\n",
    "If the last completed epoch was number 100, the training can be resumed by specifying `--RESUME=100` in the training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpretrain/v1.0/dinov2/vit-giant-p14_dinov2-pre_3rdparty_20230426-2934a630.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.mask_token\n",
      "\n",
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/SAVE//model_000001.pth\n",
      "Do not create a new experiment dir, instead use /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\n",
      "[INFO: main.py:  268]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  401]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  401]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  401]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 4033 out of 4734 in 2014-06-25-16-45-34_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 338\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5597 out of 6001 in 2014-07-14-14-49-50_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5345 out of 6000 in 2014-07-14-15-42-55_stereo_centre_03\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5801 out of 6001 in 2014-08-08-13-15-11_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 1168 out of 1168 in 2014-08-11-10-59-18_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 83\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5134 out of 6000 in 2014-11-14-16-34-33_stereo_centre_06\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5724 out of 6000 in 2014-11-18-13-20-12_stereo_centre_05\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 4804 out of 6001 in 2014-11-21-16-07-03_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5710 out of 6001 in 2014-12-09-13-21-02_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5611 out of 6000 in 2015-02-03-08-45-10_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5473 out of 6000 in 2015-02-03-19-43-11_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5431 out of 6000 in 2015-02-06-13-57-16_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5316 out of 6000 in 2015-02-13-09-16-26_stereo_centre_05\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5859 out of 6000 in 2015-02-24-12-32-19_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5133 out of 6001 in 2015-03-03-11-31-36_stereo_centre_01\n",
      "[INFO: datasets.py:  495]: number of start frames: 428\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  292]: Done Loading Train Dataset\n",
      "[INFO: utils_ssl.py:   28]: Saved ulb indices at ulb_split_indices/ulb_indices_ssl-unlbl-prop-0.0-10-23-08-04-29.pkl\n",
      "[INFO: datasets.py:  401]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  401]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  401]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 47\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04\n",
      "[INFO: datasets.py:  495]: number of start frames: 47\n",
      "[INFO: datasets.py:  488]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02\n",
      "[INFO: datasets.py:  495]: number of start frames: 47\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  323]: Done Loading Dataset Validation Dataset\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Cell anchors\n",
      " BufferList()\n",
      "kernel_size 5\n",
      "kernel_size 5\n",
      "kernel_size 7\n",
      "[INFO: main.py:  342]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  342]: ARCH: resnet50\n",
      "[INFO: main.py:  342]: BATCH_SIZE: 8\n",
      "[INFO: main.py:  342]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  342]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  342]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  342]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  342]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  342]: DATASET: road\n",
      "[INFO: main.py:  342]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  342]: DATETIME_NOW: 2023-10-23 08:04:29.873593\n",
      "[INFO: main.py:  342]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  342]: EVAL_EPOCHS: [150]\n",
      "[INFO: main.py:  342]: EXP_NAME: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\n",
      "[INFO: main.py:  342]: FBN: True\n",
      "[INFO: main.py:  342]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  342]: GAMMA: 0.1\n",
      "[INFO: main.py:  342]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  342]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  342]: GEN_TOPK: 30\n",
      "[INFO: main.py:  342]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  342]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  342]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  342]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  342]: LOG_START: 10\n",
      "[INFO: main.py:  342]: LOG_STEP: 10\n",
      "[INFO: main.py:  342]: LR: 6e-05\n",
      "[INFO: main.py:  342]: MAN_SEED: 3407\n",
      "[INFO: main.py:  342]: MAX_EPOCHS: 25\n",
      "[INFO: main.py:  342]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  342]: MAX_SIZE: 691\n",
      "[INFO: main.py:  342]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  342]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  342]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  342]: MIN_SIZE: 512\n",
      "[INFO: main.py:  342]: MODE: train\n",
      "[INFO: main.py:  342]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  342]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  342]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  342]: MULTI_GPUS: True\n",
      "[INFO: main.py:  342]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  342]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  342]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  342]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  342]: OPTIM: ADAMW\n",
      "[INFO: main.py:  342]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  342]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  342]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  342]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  342]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  342]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  342]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  342]: RESUME: 1\n",
      "[INFO: main.py:  342]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\n",
      "[INFO: main.py:  342]: SEQ_LEN: 16\n",
      "[INFO: main.py:  342]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  342]: SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: TASK: 1\n",
      "[INFO: main.py:  342]: TENSORBOARD: 1\n",
      "[INFO: main.py:  342]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  342]: TEST_SEQ_LEN: 16\n",
      "[INFO: main.py:  342]: TEST_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: TOPK: 30\n",
      "[INFO: main.py:  342]: TRAIN_SUBSETS: ['train_1']\n",
      "[INFO: main.py:  342]: TRIM_METHOD: none\n",
      "[INFO: main.py:  342]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  342]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  342]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  342]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  342]: VAL_STEP: 1\n",
      "[INFO: main.py:  342]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  342]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  342]: WEIGHT_DECAY: 0.035\n",
      "[INFO: main.py:  342]: agentness_th: 0.125\n",
      "[INFO: main.py:  342]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  342]: ar: 9\n",
      "[INFO: main.py:  342]: exp_name: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\n",
      "[INFO: main.py:  342]: flow_path: /root/autodl-tmp/unimatch-master/output/road_data_flow\n",
      "[INFO: main.py:  342]: head_size: 256\n",
      "[INFO: main.py:  342]: hostname: autodl-container-5ce511b6ae-ee4ae13a\n",
      "[INFO: main.py:  342]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  342]: labelled_videos: ['2014-07-14-14-49-50_stereo_centre_01', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-24-12-32-19_stereo_centre_04']\n",
      "[INFO: main.py:  342]: log_dir: logs//root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x//\n",
      "[INFO: main.py:  342]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  342]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  342]: model_init: kinetics\n",
      "[INFO: main.py:  342]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  342]: model_subtype: RCGRU\n",
      "[INFO: main.py:  342]: modeldino: True\n",
      "[INFO: main.py:  342]: modelswin: False\n",
      "[INFO: main.py:  342]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  342]: num_classes: 42\n",
      "[INFO: main.py:  342]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  342]: num_label_types: 4\n",
      "[INFO: main.py:  342]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  342]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\n",
      "[INFO: main.py:  342]: pretrained_model_pathfpn: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/yolox_l.pth\n",
      "[INFO: main.py:  342]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  342]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  342]: user: root\n",
      "backbone.backbone.tconv.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.deconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.flowbackbone.norm3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.flowbackbone.norm3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime1.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime1.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime2.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime2.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.catconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv1.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.lateral_conv0.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.reduce_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead4.conv.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.bias is trained at the rate of 0.00012\n",
      "reg_heads.2.weight is trained at the rate of 6e-05\n",
      "reg_heads.2.bias is trained at the rate of 0.00012\n",
      "reg_heads.4.weight is trained at the rate of 6e-05\n",
      "reg_heads.4.bias is trained at the rate of 0.00012\n",
      "reg_heads.6.weight is trained at the rate of 6e-05\n",
      "reg_heads.6.bias is trained at the rate of 0.00012\n",
      "cls_heads.0.weight is trained at the rate of 6e-05\n",
      "cls_heads.0.bias is trained at the rate of 0.00012\n",
      "cls_heads.2.weight is trained at the rate of 6e-05\n",
      "cls_heads.2.bias is trained at the rate of 0.00012\n",
      "cls_heads.4.weight is trained at the rate of 6e-05\n",
      "cls_heads.4.bias is trained at the rate of 0.00012\n",
      "cls_heads.6.weight is trained at the rate of 6e-05\n",
      "cls_heads.6.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearcls.norm1.weight is trained at the rate of 6e-05\n",
      "linearcls.norm1.bias is trained at the rate of 0.00012\n",
      "linearcls.norm2.weight is trained at the rate of 6e-05\n",
      "linearcls.norm2.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup1.norm1.weight is trained at the rate of 6e-05\n",
      "linearup1.norm1.bias is trained at the rate of 0.00012\n",
      "linearup1.norm2.weight is trained at the rate of 6e-05\n",
      "linearup1.norm2.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup2.norm1.weight is trained at the rate of 6e-05\n",
      "linearup2.norm1.bias is trained at the rate of 0.00012\n",
      "linearup2.norm2.weight is trained at the rate of 6e-05\n",
      "linearup2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm2.bias is trained at the rate of 0.00012\n",
      "[INFO: train.py:  135]: \n",
      "Lets do dataparallel\n",
      "\n",
      "[INFO: train.py:  145]: After loading checkpoint from epoch 1, the learning rate is [1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05, 1.2800000000000001e-05]\n",
      "[INFO: train.py:  155]: Created tensorboard log dir logs//root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x///log-lo_tboard-train-10-23-08-04-29_logic-Lukasiewicz_req-weight-8.0\n",
      "[INFO: train.py:  377]: \n",
      "Lets do dataparallel\n",
      "\n",
      "[INFO: train.py:  381]: OptimizedModule(\n",
      "  (_orig_mod): DataParallel(\n",
      "    (module): OptimizedModule(\n",
      "      (_orig_mod): DataParallel(\n",
      "        (module): DinoRetinaNet(\n",
      "          (anchors): anchorBox(\n",
      "            (cell_anchors): BufferList()\n",
      "          )\n",
      "          (backbone): YOLOPAFPN3DDINO(\n",
      "            (backbone): TSVideoSwinBackbone(\n",
      "              (rgbbackbone): viedoDINORGB(\n",
      "                (dinobackbone): VisionTransformer(\n",
      "                  (patch_embed): PatchEmbed(\n",
      "                    (adaptive_padding): AdaptivePadding()\n",
      "                    (projection): Conv2d(3, 1536, kernel_size=(14, 14), stride=(14, 14))\n",
      "                  )\n",
      "                  (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
      "                  (layers): ModuleList(\n",
      "                    (0-39): 40 x TransformerEncoderLayer(\n",
      "                      (ln1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "                      (attn): MultiheadAttention(\n",
      "                        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (out_drop): DropPath()\n",
      "                        (gamma1): LayerScale()\n",
      "                      )\n",
      "                      (ln2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "                      (ffn): SwiGLUFFNFused(\n",
      "                        (w12): Linear(in_features=1536, out_features=8192, bias=True)\n",
      "                        (norm): Identity()\n",
      "                        (w3): Linear(in_features=4096, out_features=1536, bias=True)\n",
      "                        (gamma2): LayerScale()\n",
      "                        (dropout_layer): Identity()\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (pre_norm): Identity()\n",
      "                  (ln1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "              (tconv): TimeGlobalMultiScaleBlock(\n",
      "                (tconv1): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1536, 1536, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "                )\n",
      "                (tconv2): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1536, 1536, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "                )\n",
      "                (tconv3): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1536, 1536, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "                )\n",
      "                (tavg): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(4608, 1536, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                )\n",
      "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (tconv_1): TimeGlobalMultiScaleBlock(\n",
      "                (tconv1): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "                )\n",
      "                (tconv2): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(256, 256, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "                )\n",
      "                (tconv3): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(256, 256, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "                )\n",
      "                (tavg): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                )\n",
      "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (tconv_2): TimeGlobalMultiScaleBlock(\n",
      "                (tconv1): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "                )\n",
      "                (tconv2): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(512, 512, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "                )\n",
      "                (tconv3): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(512, 512, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "                )\n",
      "                (tavg): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1536, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                )\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (tconv_3): TimeGlobalMultiScaleBlock(\n",
      "                (tconv1): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1024, 1024, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "                )\n",
      "                (tconv2): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1024, 1024, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0))\n",
      "                )\n",
      "                (tconv3): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(1024, 1024, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0))\n",
      "                )\n",
      "                (tavg): BaseOnlyConv3D(\n",
      "                  (conv): Conv3d(3072, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                )\n",
      "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (conv2): BaseConv3DDINO(\n",
      "                (conv): Conv3d(1536, 768, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (deconv3): BaseTransConv3DDINO(\n",
      "                (conv): ConvTranspose3d(1536, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                (act): GELU(approximate='none')\n",
      "              )\n",
      "              (flowbackbone): viedoswinFlow(\n",
      "                (patch_embed): PatchEmbed3D(\n",
      "                  (proj): Conv3d(3, 192, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
      "                  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "                (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "                (swinaclayer1): BasicLayer(\n",
      "                  (blocks): ModuleList(\n",
      "                    (0): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): Identity()\n",
      "                      (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (1): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.017)\n",
      "                      (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (downsample): PatchMerging(\n",
      "                    (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "                    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (swinaclayer2): BasicLayer(\n",
      "                  (blocks): ModuleList(\n",
      "                    (0): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.035)\n",
      "                      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (1): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.052)\n",
      "                      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (downsample): PatchMerging(\n",
      "                    (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "                    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (swinaclayer3): BasicLayer(\n",
      "                  (blocks): ModuleList(\n",
      "                    (0): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.070)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (1): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.087)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (2): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.104)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (3): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.122)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.139)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (5): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.157)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (6): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.174)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (7): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.191)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (8): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.209)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (9): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.226)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (10): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.243)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (11): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.261)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (12): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.278)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (13): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.296)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (14): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.313)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (15): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.330)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (16): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.348)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (17): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.365)\n",
      "                      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (downsample): PatchMerging(\n",
      "                    (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "                    (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (swinaclayer4): BasicLayer(\n",
      "                  (blocks): ModuleList(\n",
      "                    (0): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.383)\n",
      "                      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (1): SwinTransformerBlock3D(\n",
      "                      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                      (attn): WindowAttention3D(\n",
      "                        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                        (softmax): Softmax(dim=-1)\n",
      "                      )\n",
      "                      (drop_path): DropPath(drop_prob=0.400)\n",
      "                      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "                      (mlp): Mlp(\n",
      "                        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                        (act): GELU(approximate='none')\n",
      "                        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                        (drop): Dropout(p=0.0, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (uptime1): ConvTranspose3d(384, 384, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "              (uptime2): ConvTranspose3d(768, 768, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "              (uptime3): ConvTranspose3d(1536, 1536, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "              (catconv1): TSAttBlock(\n",
      "                (conv): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (eca): ChannAT(\n",
      "                  (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "                  (conveca): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "              )\n",
      "              (catconv2): TSAttBlock(\n",
      "                (conv): Conv3d(1536, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (eca): ChannAT(\n",
      "                  (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "                  (conveca): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "              )\n",
      "              (catconv3): TSAttBlock(\n",
      "                (conv): Conv3d(3072, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (eca): ChannAT(\n",
      "                  (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "                  (conveca): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (upsample): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='nearest')\n",
      "            (lateral_conv0): BaseConv3D(\n",
      "              (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (C3_p4): CSPLayer3DDINO(\n",
      "              (conv1): BaseConv3D(\n",
      "                (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv3D(\n",
      "                (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv3): BaseConv3D(\n",
      "                (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (m): Sequential(\n",
      "                (0): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (2): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (reduce_conv1): BaseConv3D(\n",
      "              (conv): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (C3_p3): CSPLayer3D(\n",
      "              (conv1): BaseConv3D(\n",
      "                (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv3D(\n",
      "                (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv3): BaseConv3D(\n",
      "                (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (m): Sequential(\n",
      "                (0): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (2): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (bu_conv2): BaseConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (C3_n3): CSPLayer3D(\n",
      "              (conv1): BaseConv3D(\n",
      "                (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv3D(\n",
      "                (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv3): BaseConv3D(\n",
      "                (conv): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (m): Sequential(\n",
      "                (0): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (2): Bottleneck3D(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (bu_conv1): BaseConv3D(\n",
      "              (conv): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (C3_n4): CSPLayer3DDINO(\n",
      "              (conv1): BaseConv3D(\n",
      "                (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv3D(\n",
      "                (conv): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv3): BaseConv3D(\n",
      "                (conv): Conv3d(1024, 1024, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (m): Sequential(\n",
      "                (0): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "                (2): Bottleneck3DDINO(\n",
      "                  (conv1): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): BaseConv3D(\n",
      "                    (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "                    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (act): SiLU(inplace=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (upcovhead1): BaseOnlyConv3D(\n",
      "              (conv): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            )\n",
      "            (upcovhead2): BaseOnlyConv3D(\n",
      "              (conv): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            )\n",
      "            (upcovhead3): BaseOnlyConv3D(\n",
      "              (conv): Conv3d(1024, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (upcovhead4): BaseOnlyConv3D(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (reg_heads): Sequential(\n",
      "            (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (5): GELU(approximate='none')\n",
      "            (6): Conv3d(256, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          )\n",
      "          (cls_heads): Sequential(\n",
      "            (0): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv3d(257, 257, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (5): GELU(approximate='none')\n",
      "            (6): Conv3d(257, 378, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          )\n",
      "          (linearcls): dinov2linear(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (linearup1): dinov2linearFix(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=5632, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=5632, out_features=5632, bias=True)\n",
      "            (norm1): LayerNorm((5632,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((5632,), eps=1e-05, elementwise_affine=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "          )\n",
      "          (linearup2): dinov2linearFix(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=1408, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "            (norm1): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "          )\n",
      "          (lineardown1): dinov2linearFix(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=352, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=352, out_features=352, bias=True)\n",
      "            (norm1): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "          )\n",
      "          (lineardown2): dinov2linearFix(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=88, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=88, out_features=88, bias=True)\n",
      "            (norm1): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "          )\n",
      "          (lineardown3): dinov2linearFix(\n",
      "            (linearcls1): Linear(in_features=1536, out_features=24, bias=True)\n",
      "            (liclsact1): GELU(approximate='none')\n",
      "            (linearcls2): Linear(in_features=24, out_features=24, bias=True)\n",
      "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "            (liclsact2): GELU(approximate='none')\n",
      "          )\n",
      "          (criterion): FocalLoss()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO: train.py:  382]: \n",
      "\n",
      "Solver configs are as follow \n",
      "\n",
      "\n",
      "backbone.backbone.tconv.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_1.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_1.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_2.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_2.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv1.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv2.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.tconv3.conv.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.tconv_3.tavg.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.tconv_3.norm.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.conv2.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.deconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.deconv3.ln.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.flowbackbone.norm3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.flowbackbone.norm3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime1.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime1.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime2.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime2.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.uptime3.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.uptime3.bias is trained at the rate of 0.00012\n",
      "backbone.backbone.catconv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv1.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv2.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.backbone.catconv3.eca.conveca.weight is trained at the rate of 6e-05\n",
      "backbone.lateral_conv0.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.reduce_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_p3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n3.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.bu_conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.conv3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.0.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.1.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.C3_n4.m.2.conv2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead1.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead2.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead3.conv.weight is trained at the rate of 6e-05\n",
      "backbone.upcovhead4.conv.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.weight is trained at the rate of 6e-05\n",
      "reg_heads.0.bias is trained at the rate of 0.00012\n",
      "reg_heads.2.weight is trained at the rate of 6e-05\n",
      "reg_heads.2.bias is trained at the rate of 0.00012\n",
      "reg_heads.4.weight is trained at the rate of 6e-05\n",
      "reg_heads.4.bias is trained at the rate of 0.00012\n",
      "reg_heads.6.weight is trained at the rate of 6e-05\n",
      "reg_heads.6.bias is trained at the rate of 0.00012\n",
      "cls_heads.0.weight is trained at the rate of 6e-05\n",
      "cls_heads.0.bias is trained at the rate of 0.00012\n",
      "cls_heads.2.weight is trained at the rate of 6e-05\n",
      "cls_heads.2.bias is trained at the rate of 0.00012\n",
      "cls_heads.4.weight is trained at the rate of 6e-05\n",
      "cls_heads.4.bias is trained at the rate of 0.00012\n",
      "cls_heads.6.weight is trained at the rate of 6e-05\n",
      "cls_heads.6.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearcls.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearcls.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearcls.norm1.weight is trained at the rate of 6e-05\n",
      "linearcls.norm1.bias is trained at the rate of 0.00012\n",
      "linearcls.norm2.weight is trained at the rate of 6e-05\n",
      "linearcls.norm2.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup1.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup1.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup1.norm1.weight is trained at the rate of 6e-05\n",
      "linearup1.norm1.bias is trained at the rate of 0.00012\n",
      "linearup1.norm2.weight is trained at the rate of 6e-05\n",
      "linearup1.norm2.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls1.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls1.bias is trained at the rate of 0.00012\n",
      "linearup2.linearcls2.weight is trained at the rate of 6e-05\n",
      "linearup2.linearcls2.bias is trained at the rate of 0.00012\n",
      "linearup2.norm1.weight is trained at the rate of 6e-05\n",
      "linearup2.norm1.bias is trained at the rate of 0.00012\n",
      "linearup2.norm2.weight is trained at the rate of 6e-05\n",
      "linearup2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown1.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown1.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown1.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown1.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown2.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown2.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown2.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown2.norm2.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls1.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls1.bias is trained at the rate of 0.00012\n",
      "lineardown3.linearcls2.weight is trained at the rate of 6e-05\n",
      "lineardown3.linearcls2.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm1.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm1.bias is trained at the rate of 0.00012\n",
      "lineardown3.norm2.weight is trained at the rate of 6e-05\n",
      "lineardown3.norm2.bias is trained at the rate of 0.00012\n",
      "optimizer is ADAMW\n",
      "Done solver configs\n",
      "\n",
      "\n",
      "[INFO: train.py:  384]: EXPERIMENT NAME:: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\n",
      "[INFO: train.py:  385]: Training FPN with resnet50 + RCGRU as backbone \n",
      "LR at epoch 2 is [1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06, 1.0737499999999999e-06]\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 363, in <module>\n",
      "    main()\n",
      "  File \"main.py\", line 354, in main\n",
      "    train(args, net, mixed_train_dataset, val_dataset)\n",
      "  File \"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/train.py\", line 463, in train\n",
      "    net.module.backbone.backbone.apply(utils.set_bn_eval)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py\", line 79, in __getattr__\n",
      "    return getattr(self._orig_mod, name)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1614, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'DataParallel' object has no attribute 'backbone'\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=1\n",
    "EXP_ID=\"task1\"\n",
    "EXP_NAME=\"../root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_5.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-09-26-15-06-34x/\"\n",
    "\n",
    "! python main.py --TASK=1 --EXP_NAME=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s16x1x1-roadt1-h3x3x3-10-23-00-01-20x/\" --RESUME=1 --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE/\" --MODE=\"train\" --LOGIC=\"Lukasiewicz\" --VAL_STEP=1 --LR=6e-5 --MAX_EPOCHS=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Similarly to resuming the training, the experiment's path must be provided in the `EXP_NAME` argument.\n",
    "Additionally, the `MODE` argument must be set to \"gen_dets\" and `TEST_SUBSETS` to \"test\".\n",
    "\n",
    "To evaluate the model at epoch 130, provide `--EVAL_EPOCHS=130` in the command line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 12, in <module>\n",
      "    from gen_dets import gen_dets\n",
      "ImportError: cannot import name 'gen_dets' from 'gen_dets' (/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/gen_dets.py)\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=1\n",
    "EXP_ID=\"task1\"\n",
    "EXP_NAME=\"../experiments/task1/\"\n",
    "\n",
    "! python main.py --RESUME=20 --TASK=1 --LOGIC=\"Lukasiewicz\" --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE/\" --MODE=\"gen_dets\" --TEST_SUBSETS=test --EVAL_EPOCHS=20 --EXP_NAME=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b8s12x1x1-roadt1-h3x3x3-10-23-09-28-54x/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
