{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "To train the model, provide the following positional arguments:\n",
    "   - `TASK`: set to 2 to use all 15 videos from the training partition train_1.\n",
    "   - `DATA_ROOT`: path to a directory in which `road` can be found, containing `road_test_v1.0.json`, `road_trainval_v1.0.json`, and directories `rgb-images` and `videos`.\n",
    "   - `SAVE_ROOT`: path to a directory in which the experiments (e.g. checkpoints, training logs) will be saved.\n",
    "   - `MODEL_PATH`: path to the directory containing the weights for the chosen backbone (e.g. `resnet50RCGRU.pth`).\n",
    "\n",
    "The remaining arguments are optional and include `MODEL_TYPE`, `BATCH_SIZE`, `MAX_EPOCHS`, `LOGIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Example (a): training without t-norm-based loss.\n",
    "DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/road/\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"F:/gta5/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "pretrained_model_path=\"F:\\\\gta5\\\\swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\"\n",
    "pretrained_model_path2=\"F:\\\\A-ROAD-CHALL\\\\weights\\\\weights_task1\\\\pretrained_weights_task2.pth\"\n",
    "SAVE_ROOT=\"F:/A-ROAD-CHALL/new_video_test/SAVE/\"\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"None\"\n",
    "\n",
    "! python main.py --TASK=2 --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE2/\" --MODE=\"train\" --LOGIC=\"None\" --VAL_STEP=1 --LR=0.0008 --MAX_EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "Create:  /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  264]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 4033 out of 4734 in 2014-06-25-16-45-34_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 591\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5597 out of 6001 in 2014-07-14-14-49-50_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5345 out of 6000 in 2014-07-14-15-42-55_stereo_centre_03\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5801 out of 6001 in 2014-08-08-13-15-11_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 1168 out of 1168 in 2014-08-11-10-59-18_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 146\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5134 out of 6000 in 2014-11-14-16-34-33_stereo_centre_06\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5724 out of 6000 in 2014-11-18-13-20-12_stereo_centre_05\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 4804 out of 6001 in 2014-11-21-16-07-03_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5710 out of 6001 in 2014-12-09-13-21-02_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5611 out of 6000 in 2015-02-03-08-45-10_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5473 out of 6000 in 2015-02-03-19-43-11_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5431 out of 6000 in 2015-02-06-13-57-16_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5316 out of 6000 in 2015-02-13-09-16-26_stereo_centre_05\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5859 out of 6000 in 2015-02-24-12-32-19_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5133 out of 6001 in 2015-03-03-11-31-36_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  288]: Done Loading Train Dataset\n",
      "[INFO: utils_ssl.py:   28]: Saved ulb indices at ulb_split_indices/ulb_indices_ssl-unlbl-prop-0.0-10-03-17-52-36.pkl\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  319]: Done Loading Dataset Validation Dataset\n",
      "[INFO: main.py:  338]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  338]: ARCH: resnet50\n",
      "[INFO: main.py:  338]: BATCH_SIZE: 20\n",
      "[INFO: main.py:  338]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  338]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  338]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  338]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: DATASET: road\n",
      "[INFO: main.py:  338]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  338]: DATETIME_NOW: 2023-10-03 17:52:36.137084\n",
      "[INFO: main.py:  338]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  338]: EVAL_EPOCHS: [150]\n",
      "[INFO: main.py:  338]: EXP_NAME: \n",
      "[INFO: main.py:  338]: FBN: True\n",
      "[INFO: main.py:  338]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  338]: GAMMA: 0.1\n",
      "[INFO: main.py:  338]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  338]: GEN_TOPK: 10\n",
      "[INFO: main.py:  338]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  338]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  338]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  338]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  338]: LOG_START: 10\n",
      "[INFO: main.py:  338]: LOG_STEP: 10\n",
      "[INFO: main.py:  338]: LR: 0.00012\n",
      "[INFO: main.py:  338]: MAN_SEED: 42\n",
      "[INFO: main.py:  338]: MAX_EPOCHS: 35\n",
      "[INFO: main.py:  338]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MAX_SIZE: 691\n",
      "[INFO: main.py:  338]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  338]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  338]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MIN_SIZE: 512\n",
      "[INFO: main.py:  338]: MODE: train\n",
      "[INFO: main.py:  338]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  338]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  338]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  338]: MULTI_GPUS: False\n",
      "[INFO: main.py:  338]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  338]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  338]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  338]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  338]: OPTIM: ADAMW\n",
      "[INFO: main.py:  338]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  338]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  338]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  338]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  338]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  338]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  338]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: RESUME: 0\n",
      "[INFO: main.py:  338]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: SEQ_LEN: 8\n",
      "[INFO: main.py:  338]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  338]: SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: TASK: 2\n",
      "[INFO: main.py:  338]: TENSORBOARD: 1\n",
      "[INFO: main.py:  338]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  338]: TEST_SEQ_LEN: 8\n",
      "[INFO: main.py:  338]: TEST_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: TOPK: 10\n",
      "[INFO: main.py:  338]: TRAIN_SUBSETS: ['train_1', 'train_2', 'train_3']\n",
      "[INFO: main.py:  338]: TRIM_METHOD: none\n",
      "[INFO: main.py:  338]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  338]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  338]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  338]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  338]: VAL_STEP: 1\n",
      "[INFO: main.py:  338]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  338]: WEIGHT_DECAY: 0.005\n",
      "[INFO: main.py:  338]: agentness_th: 0.125\n",
      "[INFO: main.py:  338]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  338]: ar: 9\n",
      "[INFO: main.py:  338]: exp_name: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x\n",
      "[INFO: main.py:  338]: head_size: 256\n",
      "[INFO: main.py:  338]: hostname: autodl-container-cec311b53c-6e128526\n",
      "[INFO: main.py:  338]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  338]: labelled_videos: ['2014-06-25-16-45-34_stereo_centre_02', '2014-07-14-14-49-50_stereo_centre_01', '2014-07-14-15-42-55_stereo_centre_03', '2014-08-08-13-15-11_stereo_centre_01', '2014-08-11-10-59-18_stereo_centre_02', '2014-11-14-16-34-33_stereo_centre_06', '2014-11-18-13-20-12_stereo_centre_05', '2014-11-21-16-07-03_stereo_centre_01', '2014-12-09-13-21-02_stereo_centre_01', '2015-02-03-08-45-10_stereo_centre_02', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-06-13-57-16_stereo_centre_02', '2015-02-13-09-16-26_stereo_centre_05', '2015-02-24-12-32-19_stereo_centre_04', '2015-03-03-11-31-36_stereo_centre_01', '2014-06-26-09-53-12_stereo_centre_02', '2014-11-25-09-18-32_stereo_centre_04', '2015-02-13-09-16-26_stereo_centre_02']\n",
      "[INFO: main.py:  338]: log_dir: logs/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  338]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  338]: model_init: kinetics\n",
      "[INFO: main.py:  338]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  338]: model_subtype: RCGRU\n",
      "[INFO: main.py:  338]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  338]: num_classes: 42\n",
      "[INFO: main.py:  338]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  338]: num_label_types: 4\n",
      "[INFO: main.py:  338]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  338]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\n",
      "[INFO: main.py:  338]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  338]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  338]: user: root\n",
      "backbone.upcov1.weight is trained at the rate of 0.00012\n",
      "backbone.upcov1.bias is trained at the rate of 0.00024\n",
      "backbone.upcov2.weight is trained at the rate of 0.00012\n",
      "backbone.upcov2.bias is trained at the rate of 0.00024\n",
      "backbone.upcov3.weight is trained at the rate of 0.00012\n",
      "backbone.upcov3.bias is trained at the rate of 0.00024\n",
      "backbone.upcov4.weight is trained at the rate of 0.00012\n",
      "backbone.upcov4.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.conv6.weight is trained at the rate of 0.00012\n",
      "backbone.conv7.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer3.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer3.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.bias is trained at the rate of 0.00024\n",
      "reg_heads.2.weight is trained at the rate of 0.00012\n",
      "reg_heads.2.bias is trained at the rate of 0.00024\n",
      "reg_heads.4.weight is trained at the rate of 0.00012\n",
      "reg_heads.4.bias is trained at the rate of 0.00024\n",
      "reg_heads.6.weight is trained at the rate of 0.00012\n",
      "reg_heads.6.bias is trained at the rate of 0.00024\n",
      "cls_heads.0.weight is trained at the rate of 0.00012\n",
      "cls_heads.0.bias is trained at the rate of 0.00024\n",
      "cls_heads.2.weight is trained at the rate of 0.00012\n",
      "cls_heads.2.bias is trained at the rate of 0.00024\n",
      "cls_heads.4.weight is trained at the rate of 0.00012\n",
      "cls_heads.4.bias is trained at the rate of 0.00024\n",
      "cls_heads.6.weight is trained at the rate of 0.00012\n",
      "cls_heads.6.bias is trained at the rate of 0.00024\n",
      "[INFO: train.py:   62]: Created tensorboard log dir logs/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x//log-lo_tboard-train-10-03-17-52-36_logic-Lukasiewicz_req-weight-8.0\n",
      "missing\n",
      "['backbone.upcov1.weight', 'backbone.upcov1.bias', 'backbone.upcov2.weight', 'backbone.upcov2.bias', 'backbone.upcov3.weight', 'backbone.upcov3.bias', 'backbone.upcov4.weight', 'backbone.upcov4.bias']\n",
      "unexpcted\n",
      "[]\n",
      "[INFO: train.py:  160]: Load pretrained model /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: train.py:  162]: RetinaNet(\n",
      "  (anchors): anchorBox(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      "  (backbone): ResNetFPN(\n",
      "    (patch_embed): PatchEmbed3D(\n",
      "      (proj): Conv3d(3, 192, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (swinaclayer1): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.017)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer2): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.035)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.052)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer3): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.070)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.104)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.122)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.139)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.157)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.174)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.191)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.209)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.226)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.243)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.261)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.278)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.296)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.313)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.330)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.348)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.365)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer4): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.383)\n",
      "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.400)\n",
      "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (upcov1): ConvTranspose3d(384, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov2): ConvTranspose3d(768, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov3): ConvTranspose3d(1536, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov4): ConvTranspose3d(1536, 2048, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "    (layer1): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv6): Conv3d(2048, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "    (conv7): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "    (avg_pool): AdaptiveAvgPool3d(output_size=(None, 1, 1))\n",
      "    (lateral_layer1): Conv3d(2048, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (lateral_layer2): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (lateral_layer3): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (corr_layer1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "    (corr_layer2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "    (corr_layer3): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "  )\n",
      "  (reg_heads): Sequential(\n",
      "    (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv3d(256, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (cls_heads): Sequential(\n",
      "    (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv3d(256, 378, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (criterion): FocalLoss()\n",
      ")\n",
      "[INFO: train.py:  163]: \n",
      "\n",
      "Solver configs are as follow \n",
      "\n",
      "\n",
      "backbone.upcov1.weight is trained at the rate of 0.00012\n",
      "backbone.upcov1.bias is trained at the rate of 0.00024\n",
      "backbone.upcov2.weight is trained at the rate of 0.00012\n",
      "backbone.upcov2.bias is trained at the rate of 0.00024\n",
      "backbone.upcov3.weight is trained at the rate of 0.00012\n",
      "backbone.upcov3.bias is trained at the rate of 0.00024\n",
      "backbone.upcov4.weight is trained at the rate of 0.00012\n",
      "backbone.upcov4.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.conv6.weight is trained at the rate of 0.00012\n",
      "backbone.conv7.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer3.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer3.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.bias is trained at the rate of 0.00024\n",
      "reg_heads.2.weight is trained at the rate of 0.00012\n",
      "reg_heads.2.bias is trained at the rate of 0.00024\n",
      "reg_heads.4.weight is trained at the rate of 0.00012\n",
      "reg_heads.4.bias is trained at the rate of 0.00024\n",
      "reg_heads.6.weight is trained at the rate of 0.00012\n",
      "reg_heads.6.bias is trained at the rate of 0.00024\n",
      "cls_heads.0.weight is trained at the rate of 0.00012\n",
      "cls_heads.0.bias is trained at the rate of 0.00024\n",
      "cls_heads.2.weight is trained at the rate of 0.00012\n",
      "cls_heads.2.bias is trained at the rate of 0.00024\n",
      "cls_heads.4.weight is trained at the rate of 0.00012\n",
      "cls_heads.4.bias is trained at the rate of 0.00024\n",
      "cls_heads.6.weight is trained at the rate of 0.00012\n",
      "cls_heads.6.bias is trained at the rate of 0.00024\n",
      "optimizer is ADAMW\n",
      "Done solver configs\n",
      "\n",
      "\n",
      "[INFO: train.py:  165]: EXPERIMENT NAME:: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x\n",
      "[INFO: train.py:  166]: Training FPN with resnet50 + RCGRU as backbone \n",
      "LR at epoch 1 is [0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024]\n",
      "[INFO: train.py:  355]: Iteration [1/35]000010/000636 losses for all loc-loss 0.98(1.19) cls-loss 0.54(2.59) req-loss 0.00455445(0.00587929) overall-loss 1.53(3.79)\n",
      "[INFO: train.py:  365]: DataTime 0.01(67.81) Timer 66.57(178.61)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000020/000636 losses for all loc-loss 0.87(1.08) cls-loss 0.40(1.73) req-loss 0.00173259(0.00492149) overall-loss 1.28(2.82)\n",
      "[INFO: train.py:  365]: DataTime 0.00(40.61) Timer 66.84(133.55)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000030/000636 losses for all loc-loss 0.82(0.99) cls-loss 0.40(1.21) req-loss 0.00081420(0.00338782) overall-loss 1.22(2.21)\n",
      "[INFO: train.py:  365]: DataTime 0.01(24.31) Timer 66.53(106.67)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000040/000636 losses for all loc-loss 0.76(0.91) cls-loss 0.40(0.90) req-loss 0.00046974(0.00231857) overall-loss 1.16(1.81)\n",
      "[INFO: train.py:  365]: DataTime 0.00(14.56) Timer 66.45(90.56)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000050/000636 losses for all loc-loss 0.73(0.86) cls-loss 0.37(0.69) req-loss 0.00068098(0.00181188) overall-loss 1.09(1.56)\n",
      "[INFO: train.py:  365]: DataTime 0.01(8.72) Timer 67.29(80.96)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000060/000636 losses for all loc-loss 0.72(0.81) cls-loss 0.34(0.56) req-loss 0.00113773(0.00159260) overall-loss 1.07(1.37)\n",
      "[INFO: train.py:  365]: DataTime 0.01(5.22) Timer 67.61(75.47)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000070/000636 losses for all loc-loss 0.73(0.77) cls-loss 0.32(0.47) req-loss 0.00151813(0.00150150) overall-loss 1.05(1.24)\n",
      "[INFO: train.py:  365]: DataTime 0.01(3.13) Timer 73.58(73.07)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000080/000636 losses for all loc-loss 0.67(0.74) cls-loss 0.30(0.41) req-loss 0.00123960(0.00146235) overall-loss 0.97(1.15)\n",
      "[INFO: train.py:  365]: DataTime 0.00(1.88) Timer 69.31(72.18)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000090/000636 losses for all loc-loss 0.65(0.71) cls-loss 0.32(0.37) req-loss 0.00100917(0.00130037) overall-loss 0.97(1.09)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.13) Timer 70.41(71.48)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000100/000636 losses for all loc-loss 0.64(0.69) cls-loss 0.30(0.34) req-loss 0.00096959(0.00124238) overall-loss 0.94(1.04)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.68) Timer 72.40(71.35)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000110/000636 losses for all loc-loss 0.62(0.67) cls-loss 0.28(0.32) req-loss 0.00113958(0.00115965) overall-loss 0.90(0.99)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.41) Timer 73.50(71.15)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000120/000636 losses for all loc-loss 0.58(0.65) cls-loss 0.26(0.30) req-loss 0.00115633(0.00113763) overall-loss 0.84(0.96)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.25) Timer 71.96(71.13)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000130/000636 losses for all loc-loss 0.62(0.64) cls-loss 0.29(0.29) req-loss 0.00088030(0.00112265) overall-loss 0.91(0.94)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.15) Timer 70.65(70.83)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000140/000636 losses for all loc-loss 0.55(0.63) cls-loss 0.26(0.28) req-loss 0.00130427(0.00111639) overall-loss 0.81(0.91)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.09) Timer 69.16(70.77)\n",
      "[INFO: train.py:  355]: Iteration [1/35]000150/000636 losses for all loc-loss 0.56(0.62) cls-loss 0.24(0.27) req-loss 0.00136101(0.00113964) overall-loss 0.80(0.90)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.06) Timer 73.70(71.24)\n"
     ]
    }
   ],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "! python main.py --TASK=2 --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE/\" --MODE=\"train\" --LOGIC=\"Lukasiewicz\" --VAL_STEP=1 --LR=0.00012 --MAX_EPOCHS=35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming the training\n",
    "To resume the training of a model, provide the path to the directory containing the checkpoint from which the experiment should be resumed in the `EXP_NAME` argument.\n",
    "If the last completed epoch was number 15, the training can be resumed by specifying `--RESUME=15` in the training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "EXP_NAME=\"../experiments/task2/road/logic-ssl_cache_Lukasiewicz_10.0/resnet50RCGRU512-Pkinetics-b4s8x1x1-roadt1-h3x3x3-05-01-01-01-01x/\"\n",
    "\n",
    "! python main.py {TASK} {DATA_ROOT} {EXPDIR}/{EXP_ID}/ {MODEL_PATH} --MODE=\"train\" --VAL_STEP=2 --LR=0.0041 --MAX_EPOCHS=30 --MILESTONES=20,25 --LOGIC={LOGIC} --EXP_NAME={EXP_NAME} --RESUME=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Similarly to resuming the training, the experiment's path must be provided in the `EXP_NAME` argument.\n",
    "Additionally, the `MODE` argument must be set to \"gen_dets\" and `TEST_SUBSETS` to \"test\".\n",
    "\n",
    "To evaluate the model at epoch 130, provide `--EVAL_EPOCHS=130` in the command line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE2/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/SAVE2//model_000015.pth\n",
      "Do not create a new experiment dir, instead use /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  264]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6000 in 2014-06-26-09-31-18_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6000 in 2014-12-10-18-10-50_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 3000 in 2015-02-03-08-45-10_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 39\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6001 in 2015-02-06-13-57-16_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  319]: Done Loading Dataset Validation Dataset\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "[INFO: main.py:  338]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  338]: ARCH: resnet50\n",
      "[INFO: main.py:  338]: BATCH_SIZE: 20\n",
      "[INFO: main.py:  338]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  338]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  338]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  338]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: DATASET: road\n",
      "[INFO: main.py:  338]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  338]: DATETIME_NOW: 2023-10-05 11:38:31.544796\n",
      "[INFO: main.py:  338]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  338]: EVAL_EPOCHS: [15]\n",
      "[INFO: main.py:  338]: EXP_NAME: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: FBN: True\n",
      "[INFO: main.py:  338]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  338]: GAMMA: 0.1\n",
      "[INFO: main.py:  338]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  338]: GEN_TOPK: 30\n",
      "[INFO: main.py:  338]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  338]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  338]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  338]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  338]: LOG_START: 10\n",
      "[INFO: main.py:  338]: LOG_STEP: 10\n",
      "[INFO: main.py:  338]: LR: 0.00041\n",
      "[INFO: main.py:  338]: MAN_SEED: 42\n",
      "[INFO: main.py:  338]: MAX_EPOCHS: 150\n",
      "[INFO: main.py:  338]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MAX_SIZE: 691\n",
      "[INFO: main.py:  338]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  338]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  338]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MIN_SIZE: 512\n",
      "[INFO: main.py:  338]: MODE: gen_dets\n",
      "[INFO: main.py:  338]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  338]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  338]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  338]: MULTI_GPUS: False\n",
      "[INFO: main.py:  338]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  338]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  338]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  338]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  338]: OPTIM: ADAMW\n",
      "[INFO: main.py:  338]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  338]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  338]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  338]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  338]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  338]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  338]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: RESUME: 15\n",
      "[INFO: main.py:  338]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: SEQ_LEN: 80\n",
      "[INFO: main.py:  338]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  338]: SUBSETS: ['test']\n",
      "[INFO: main.py:  338]: TASK: 2\n",
      "[INFO: main.py:  338]: TENSORBOARD: 1\n",
      "[INFO: main.py:  338]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  338]: TEST_SEQ_LEN: 80\n",
      "[INFO: main.py:  338]: TEST_SUBSETS: ['test']\n",
      "[INFO: main.py:  338]: TOPK: 30\n",
      "[INFO: main.py:  338]: TRAIN_SUBSETS: ['train_1', 'train_2', 'train_3']\n",
      "[INFO: main.py:  338]: TRIM_METHOD: none\n",
      "[INFO: main.py:  338]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  338]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  338]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  338]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  338]: VAL_STEP: 10\n",
      "[INFO: main.py:  338]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  338]: WEIGHT_DECAY: 0.005\n",
      "[INFO: main.py:  338]: agentness_th: 0.125\n",
      "[INFO: main.py:  338]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  338]: ar: 9\n",
      "[INFO: main.py:  338]: exp_name: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: head_size: 256\n",
      "[INFO: main.py:  338]: hostname: autodl-container-cec311b53c-6e128526\n",
      "[INFO: main.py:  338]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  338]: labelled_videos: ['2014-06-25-16-45-34_stereo_centre_02', '2014-07-14-14-49-50_stereo_centre_01', '2014-07-14-15-42-55_stereo_centre_03', '2014-08-08-13-15-11_stereo_centre_01', '2014-08-11-10-59-18_stereo_centre_02', '2014-11-14-16-34-33_stereo_centre_06', '2014-11-18-13-20-12_stereo_centre_05', '2014-11-21-16-07-03_stereo_centre_01', '2014-12-09-13-21-02_stereo_centre_01', '2015-02-03-08-45-10_stereo_centre_02', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-06-13-57-16_stereo_centre_02', '2015-02-13-09-16-26_stereo_centre_05', '2015-02-24-12-32-19_stereo_centre_04', '2015-03-03-11-31-36_stereo_centre_01', '2014-06-26-09-53-12_stereo_centre_02', '2014-11-25-09-18-32_stereo_centre_04', '2015-02-13-09-16-26_stereo_centre_02']\n",
      "[INFO: main.py:  338]: log_dir: logs//root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x//\n",
      "[INFO: main.py:  338]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  338]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  338]: model_init: kinetics\n",
      "[INFO: main.py:  338]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  338]: model_subtype: RCGRU\n",
      "[INFO: main.py:  338]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  338]: num_classes: 42\n",
      "[INFO: main.py:  338]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  338]: num_label_types: 4\n",
      "[INFO: main.py:  338]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  338]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\n",
      "[INFO: main.py:  338]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  338]: skip_beggning: 2\n",
      "[INFO: main.py:  338]: skip_ending: 0\n",
      "[INFO: main.py:  338]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  338]: user: root\n",
      "[INFO: gen_dets.py:   31]: Testing at 15\n",
      "[INFO: gen_dets.py:   34]: detection saving dir is :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/detections-15-80-50_test/\n",
      "[INFO: gen_dets.py:   46]: Detection saving pkl file path  :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-15-80-50_test.pkl\n",
      "[INFO: gen_dets.py:   47]: Detection saving zip file path  :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-15-80-50_test.zip\n",
      "[INFO: gen_dets.py:   75]: Finished loading model 15 !\n",
      "[INFO: gen_dets.py:  201]: Forward Time 8.537\n",
      "[INFO: gen_dets.py:  269]: im_detect: 1/270 time taken 17.641\n",
      "[INFO: gen_dets.py:  275]: NMS stuff Time 4.435\n",
      "[INFO: gen_dets.py:  201]: Forward Time 3.255\n",
      "[INFO: gen_dets.py:  269]: im_detect: 51/270 time taken 287.627\n",
      "[INFO: gen_dets.py:  275]: NMS stuff Time 1.960\n",
      "[INFO: gen_dets.py:  201]: Forward Time 3.247\n",
      "[INFO: gen_dets.py:  269]: im_detect: 101/270 time taken 362.000\n",
      "[INFO: gen_dets.py:  275]: NMS stuff Time 6.169\n",
      "[INFO: gen_dets.py:  201]: Forward Time 3.248\n",
      "[INFO: gen_dets.py:  269]: im_detect: 151/270 time taken 347.813\n",
      "[INFO: gen_dets.py:  275]: NMS stuff Time 3.631\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "EXP_NAME=\"../experiments/task2/road/logic-ssl_cache_Lukasiewicz_10.0/resnet50RCGRU512-Pkinetics-b4s8x1x1-roadt1-h3x3x3-05-01-01-01-01x/\"\n",
    "! python main.py --RESUME=21 --TASK=2 --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --TEST_SUBSETS=test --EVAL_EPOCHS=21 --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\"  --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE2/\" --EXP_NAME=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\" --MODE=\"gen_dets\" --LOGIC=\"Lukasiewicz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ! python post_processing.py --file_path=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-21-80-50_test.pkl\" --requirements_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/constraints/WDIMACS_requirements.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing the predictions\n",
    "\n",
    "To postprocess the predictions, and thus guarantee that the requirements are satisfied, use the output `.pkl` file (from `EXP_NAME`) as input to the postprocessing module, based on the [MaxHS solver](https://github.com/fbacchus/MaxHS/tree/master), from `postprocessing/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
