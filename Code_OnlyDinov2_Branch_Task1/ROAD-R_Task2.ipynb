{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "To train the model, provide the following positional arguments:\n",
    "   - `TASK`: set to 2 to use all 15 videos from the training partition train_1.\n",
    "   - `DATA_ROOT`: path to a directory in which `road` can be found, containing `road_test_v1.0.json`, `road_trainval_v1.0.json`, and directories `rgb-images` and `videos`.\n",
    "   - `SAVE_ROOT`: path to a directory in which the experiments (e.g. checkpoints, training logs) will be saved.\n",
    "   - `MODEL_PATH`: path to the directory containing the weights for the chosen backbone (e.g. `resnet50RCGRU.pth`).\n",
    "\n",
    "The remaining arguments are optional and include `MODEL_TYPE`, `BATCH_SIZE`, `MAX_EPOCHS`, `LOGIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Example (a): training without t-norm-based loss.\n",
    "DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/road/\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"F:/gta5/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "pretrained_model_path=\"F:\\\\gta5\\\\swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\"\n",
    "pretrained_model_path2=\"F:\\\\A-ROAD-CHALL\\\\weights\\\\weights_task1\\\\pretrained_weights_task2.pth\"\n",
    "SAVE_ROOT=\"F:/A-ROAD-CHALL/new_video_test/SAVE/\"\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"None\"\n",
    "\n",
    "! python main.py --TASK=2 --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE2/\" --MODE=\"train\" --LOGIC=\"None\" --VAL_STEP=1 --LR=0.0008 --MAX_EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "Create:  /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x/\n",
      "[INFO: main.py:  264]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 4033 out of 4734 in 2014-06-25-16-45-34_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 591\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5597 out of 6001 in 2014-07-14-14-49-50_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5345 out of 6000 in 2014-07-14-15-42-55_stereo_centre_03\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5801 out of 6001 in 2014-08-08-13-15-11_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 1168 out of 1168 in 2014-08-11-10-59-18_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 146\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5134 out of 6000 in 2014-11-14-16-34-33_stereo_centre_06\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5724 out of 6000 in 2014-11-18-13-20-12_stereo_centre_05\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 4804 out of 6001 in 2014-11-21-16-07-03_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5710 out of 6001 in 2014-12-09-13-21-02_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5611 out of 6000 in 2015-02-03-08-45-10_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5473 out of 6000 in 2015-02-03-19-43-11_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5431 out of 6000 in 2015-02-06-13-57-16_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5316 out of 6000 in 2015-02-13-09-16-26_stereo_centre_05\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5859 out of 6000 in 2015-02-24-12-32-19_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5133 out of 6001 in 2015-03-03-11-31-36_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 750\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  288]: Done Loading Train Dataset\n",
      "[INFO: utils_ssl.py:   28]: Saved ulb indices at ulb_split_indices/ulb_indices_ssl-unlbl-prop-0.0-10-05-19-50-33.pkl\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 94\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  319]: Done Loading Dataset Validation Dataset\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "[INFO: main.py:  338]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  338]: ARCH: resnet50\n",
      "[INFO: main.py:  338]: BATCH_SIZE: 20\n",
      "[INFO: main.py:  338]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  338]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  338]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  338]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: DATASET: road\n",
      "[INFO: main.py:  338]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  338]: DATETIME_NOW: 2023-10-05 19:50:33.679933\n",
      "[INFO: main.py:  338]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  338]: EVAL_EPOCHS: [150]\n",
      "[INFO: main.py:  338]: EXP_NAME: \n",
      "[INFO: main.py:  338]: FBN: True\n",
      "[INFO: main.py:  338]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  338]: GAMMA: 0.1\n",
      "[INFO: main.py:  338]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  338]: GEN_TOPK: 30\n",
      "[INFO: main.py:  338]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  338]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  338]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  338]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  338]: LOG_START: 10\n",
      "[INFO: main.py:  338]: LOG_STEP: 10\n",
      "[INFO: main.py:  338]: LR: 0.00012\n",
      "[INFO: main.py:  338]: MAN_SEED: 42\n",
      "[INFO: main.py:  338]: MAX_EPOCHS: 30\n",
      "[INFO: main.py:  338]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MAX_SIZE: 691\n",
      "[INFO: main.py:  338]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  338]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  338]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MIN_SIZE: 512\n",
      "[INFO: main.py:  338]: MODE: train\n",
      "[INFO: main.py:  338]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  338]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  338]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  338]: MULTI_GPUS: False\n",
      "[INFO: main.py:  338]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  338]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  338]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  338]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  338]: OPTIM: ADAMW\n",
      "[INFO: main.py:  338]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  338]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  338]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  338]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  338]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  338]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  338]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: RESUME: 0\n",
      "[INFO: main.py:  338]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x/\n",
      "[INFO: main.py:  338]: SEQ_LEN: 8\n",
      "[INFO: main.py:  338]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  338]: SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: TASK: 2\n",
      "[INFO: main.py:  338]: TENSORBOARD: 1\n",
      "[INFO: main.py:  338]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  338]: TEST_SEQ_LEN: 8\n",
      "[INFO: main.py:  338]: TEST_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: TOPK: 30\n",
      "[INFO: main.py:  338]: TRAIN_SUBSETS: ['train_1']\n",
      "[INFO: main.py:  338]: TRIM_METHOD: none\n",
      "[INFO: main.py:  338]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  338]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  338]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  338]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  338]: VAL_STEP: 1\n",
      "[INFO: main.py:  338]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  338]: WEIGHT_DECAY: 0.005\n",
      "[INFO: main.py:  338]: agentness_th: 0.125\n",
      "[INFO: main.py:  338]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  338]: ar: 9\n",
      "[INFO: main.py:  338]: exp_name: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: main.py:  338]: head_size: 256\n",
      "[INFO: main.py:  338]: hostname: autodl-container-d2c311873c-5a3dc589\n",
      "[INFO: main.py:  338]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  338]: labelled_videos: ['2014-06-25-16-45-34_stereo_centre_02', '2014-07-14-14-49-50_stereo_centre_01', '2014-07-14-15-42-55_stereo_centre_03', '2014-08-08-13-15-11_stereo_centre_01', '2014-08-11-10-59-18_stereo_centre_02', '2014-11-14-16-34-33_stereo_centre_06', '2014-11-18-13-20-12_stereo_centre_05', '2014-11-21-16-07-03_stereo_centre_01', '2014-12-09-13-21-02_stereo_centre_01', '2015-02-03-08-45-10_stereo_centre_02', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-06-13-57-16_stereo_centre_02', '2015-02-13-09-16-26_stereo_centre_05', '2015-02-24-12-32-19_stereo_centre_04', '2015-03-03-11-31-36_stereo_centre_01']\n",
      "[INFO: main.py:  338]: log_dir: logs/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x/\n",
      "[INFO: main.py:  338]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  338]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  338]: model_init: kinetics\n",
      "[INFO: main.py:  338]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  338]: model_subtype: RCGRU\n",
      "[INFO: main.py:  338]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  338]: num_classes: 42\n",
      "[INFO: main.py:  338]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  338]: num_label_types: 4\n",
      "[INFO: main.py:  338]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  338]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\n",
      "[INFO: main.py:  338]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  338]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  338]: user: root\n",
      "backbone.upcov1.weight is trained at the rate of 0.00012\n",
      "backbone.upcov1.bias is trained at the rate of 0.00024\n",
      "backbone.upcov2.weight is trained at the rate of 0.00012\n",
      "backbone.upcov2.bias is trained at the rate of 0.00024\n",
      "backbone.upcov3.weight is trained at the rate of 0.00012\n",
      "backbone.upcov3.bias is trained at the rate of 0.00024\n",
      "backbone.upcov4.weight is trained at the rate of 0.00012\n",
      "backbone.upcov4.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.conv6.weight is trained at the rate of 0.00012\n",
      "backbone.conv7.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer3.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer3.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.bias is trained at the rate of 0.00024\n",
      "reg_heads.2.weight is trained at the rate of 0.00012\n",
      "reg_heads.2.bias is trained at the rate of 0.00024\n",
      "reg_heads.4.weight is trained at the rate of 0.00012\n",
      "reg_heads.4.bias is trained at the rate of 0.00024\n",
      "reg_heads.6.weight is trained at the rate of 0.00012\n",
      "reg_heads.6.bias is trained at the rate of 0.00024\n",
      "cls_heads.0.weight is trained at the rate of 0.00012\n",
      "cls_heads.0.bias is trained at the rate of 0.00024\n",
      "cls_heads.2.weight is trained at the rate of 0.00012\n",
      "cls_heads.2.bias is trained at the rate of 0.00024\n",
      "cls_heads.4.weight is trained at the rate of 0.00012\n",
      "cls_heads.4.bias is trained at the rate of 0.00024\n",
      "cls_heads.6.weight is trained at the rate of 0.00012\n",
      "cls_heads.6.bias is trained at the rate of 0.00024\n",
      "[INFO: train.py:   62]: Created tensorboard log dir logs/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x//log-lo_tboard-train-10-05-19-50-33_logic-Lukasiewicz_req-weight-8.0\n",
      "missing\n",
      "['backbone.upcov1.weight', 'backbone.upcov1.bias', 'backbone.upcov2.weight', 'backbone.upcov2.bias', 'backbone.upcov3.weight', 'backbone.upcov3.bias', 'backbone.upcov4.weight', 'backbone.upcov4.bias']\n",
      "unexpcted\n",
      "[]\n",
      "[INFO: train.py:  160]: Load pretrained model /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: train.py:  162]: RetinaNet(\n",
      "  (anchors): anchorBox(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      "  (backbone): ResNetFPN(\n",
      "    (patch_embed): PatchEmbed3D(\n",
      "      (proj): Conv3d(3, 192, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (swinaclayer1): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.017)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer2): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.035)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.052)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer3): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.070)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.104)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.122)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.139)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.157)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.174)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.191)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.209)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.226)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.243)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.261)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.278)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.296)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.313)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.330)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.348)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.365)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (swinaclayer4): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.383)\n",
      "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock3D(\n",
      "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention3D(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.400)\n",
      "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (upcov1): ConvTranspose3d(384, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov2): ConvTranspose3d(768, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov3): ConvTranspose3d(1536, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (upcov4): ConvTranspose3d(1536, 2048, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
      "    (layer1): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (cgru): CGRU(\n",
      "          (recurrent_conv_gates): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (recurrent_conv_out): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BottleneckRCGRU(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv6): Conv3d(2048, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "    (conv7): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "    (avg_pool): AdaptiveAvgPool3d(output_size=(None, 1, 1))\n",
      "    (lateral_layer1): Conv3d(2048, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (lateral_layer2): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (lateral_layer3): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (corr_layer1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "    (corr_layer2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "    (corr_layer3): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "  )\n",
      "  (reg_heads): Sequential(\n",
      "    (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv3d(256, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (cls_heads): Sequential(\n",
      "    (0): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv3d(256, 378, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (criterion): FocalLoss()\n",
      ")\n",
      "[INFO: train.py:  163]: \n",
      "\n",
      "Solver configs are as follow \n",
      "\n",
      "\n",
      "backbone.upcov1.weight is trained at the rate of 0.00012\n",
      "backbone.upcov1.bias is trained at the rate of 0.00024\n",
      "backbone.upcov2.weight is trained at the rate of 0.00012\n",
      "backbone.upcov2.bias is trained at the rate of 0.00024\n",
      "backbone.upcov3.weight is trained at the rate of 0.00012\n",
      "backbone.upcov3.bias is trained at the rate of 0.00024\n",
      "backbone.upcov4.weight is trained at the rate of 0.00012\n",
      "backbone.upcov4.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer1.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer1.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer2.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer2.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.3.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer3.4.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.4.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer3.5.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.0.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.0.downsample.0.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_gates.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.cgru.recurrent_conv_out.bias is trained at the rate of 0.00024\n",
      "backbone.layer4.1.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.1.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv1.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv2.weight is trained at the rate of 0.00012\n",
      "backbone.layer4.2.conv3.weight is trained at the rate of 0.00012\n",
      "backbone.conv6.weight is trained at the rate of 0.00012\n",
      "backbone.conv7.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.lateral_layer3.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer1.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer2.weight is trained at the rate of 0.00012\n",
      "backbone.corr_layer3.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.weight is trained at the rate of 0.00012\n",
      "reg_heads.0.bias is trained at the rate of 0.00024\n",
      "reg_heads.2.weight is trained at the rate of 0.00012\n",
      "reg_heads.2.bias is trained at the rate of 0.00024\n",
      "reg_heads.4.weight is trained at the rate of 0.00012\n",
      "reg_heads.4.bias is trained at the rate of 0.00024\n",
      "reg_heads.6.weight is trained at the rate of 0.00012\n",
      "reg_heads.6.bias is trained at the rate of 0.00024\n",
      "cls_heads.0.weight is trained at the rate of 0.00012\n",
      "cls_heads.0.bias is trained at the rate of 0.00024\n",
      "cls_heads.2.weight is trained at the rate of 0.00012\n",
      "cls_heads.2.bias is trained at the rate of 0.00024\n",
      "cls_heads.4.weight is trained at the rate of 0.00012\n",
      "cls_heads.4.bias is trained at the rate of 0.00024\n",
      "cls_heads.6.weight is trained at the rate of 0.00012\n",
      "cls_heads.6.bias is trained at the rate of 0.00024\n",
      "optimizer is ADAMW\n",
      "Done solver configs\n",
      "\n",
      "\n",
      "[INFO: train.py:  165]: EXPERIMENT NAME:: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  166]: Training FPN with resnet50 + RCGRU as backbone \n",
      "LR at epoch 1 is [0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024, 0.00012, 0.00024]\n",
      "[INFO: train.py:  355]: Iteration [1/30]000010/000524 losses for all loc-loss 0.96(1.13) cls-loss 0.59(3.33) req-loss 0.00475246(0.00594357) overall-loss 1.56(4.46)\n",
      "[INFO: train.py:  365]: DataTime 0.01(57.49) Timer 65.53(175.01)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000020/000524 losses for all loc-loss 0.91(1.05) cls-loss 0.44(2.19) req-loss 0.00246799(0.00514245) overall-loss 1.35(3.24)\n",
      "[INFO: train.py:  365]: DataTime 0.00(34.42) Timer 66.13(131.22)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000030/000524 losses for all loc-loss 0.90(0.99) cls-loss 0.60(1.50) req-loss 0.00098497(0.00367075) overall-loss 1.50(2.49)\n",
      "[INFO: train.py:  365]: DataTime 0.01(20.61) Timer 66.12(104.97)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000040/000524 losses for all loc-loss 0.80(0.93) cls-loss 0.43(1.07) req-loss 0.00103211(0.00268898) overall-loss 1.24(2.00)\n",
      "[INFO: train.py:  365]: DataTime 0.01(12.34) Timer 65.93(89.24)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000050/000524 losses for all loc-loss 0.75(0.88) cls-loss 0.38(0.80) req-loss 0.00119346(0.00213074) overall-loss 1.14(1.68)\n",
      "[INFO: train.py:  365]: DataTime 0.00(7.39) Timer 66.35(79.87)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000060/000524 losses for all loc-loss 0.74(0.84) cls-loss 0.36(0.62) req-loss 0.00089061(0.00169662) overall-loss 1.10(1.47)\n",
      "[INFO: train.py:  365]: DataTime 0.00(4.43) Timer 66.11(74.44)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000070/000524 losses for all loc-loss 0.73(0.80) cls-loss 0.33(0.51) req-loss 0.00154889(0.00160502) overall-loss 1.06(1.32)\n",
      "[INFO: train.py:  365]: DataTime 0.01(2.65) Timer 68.95(71.77)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000080/000524 losses for all loc-loss 0.73(0.78) cls-loss 0.31(0.43) req-loss 0.00180733(0.00165632) overall-loss 1.05(1.22)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.59) Timer 71.71(71.24)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000090/000524 losses for all loc-loss 0.66(0.76) cls-loss 0.28(0.39) req-loss 0.00102878(0.00145951) overall-loss 0.94(1.15)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.96) Timer 68.51(70.71)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000100/000524 losses for all loc-loss 0.69(0.74) cls-loss 0.30(0.36) req-loss 0.00109202(0.00132437) overall-loss 0.99(1.09)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.58) Timer 72.13(70.73)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000110/000524 losses for all loc-loss 0.62(0.71) cls-loss 0.27(0.34) req-loss 0.00129634(0.00120377) overall-loss 0.89(1.05)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.35) Timer 68.09(70.44)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000120/000524 losses for all loc-loss 0.66(0.70) cls-loss 0.31(0.32) req-loss 0.00111085(0.00120921) overall-loss 0.96(1.02)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.21) Timer 69.97(70.43)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000130/000524 losses for all loc-loss 0.60(0.68) cls-loss 0.26(0.31) req-loss 0.00118881(0.00112209) overall-loss 0.86(0.98)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.13) Timer 69.96(70.01)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000140/000524 losses for all loc-loss 0.63(0.66) cls-loss 0.29(0.29) req-loss 0.00115067(0.00115834) overall-loss 0.92(0.96)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.08) Timer 71.73(69.97)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000150/000524 losses for all loc-loss 0.61(0.65) cls-loss 0.26(0.28) req-loss 0.00109679(0.00111289) overall-loss 0.86(0.94)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.05) Timer 71.01(70.46)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000160/000524 losses for all loc-loss 0.63(0.64) cls-loss 0.27(0.28) req-loss 0.00092661(0.00111762) overall-loss 0.90(0.92)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.03) Timer 67.47(69.92)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000170/000524 losses for all loc-loss 0.60(0.64) cls-loss 0.25(0.27) req-loss 0.00100470(0.00105574) overall-loss 0.85(0.92)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.02) Timer 69.35(69.73)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000180/000524 losses for all loc-loss 0.61(0.63) cls-loss 0.24(0.27) req-loss 0.00087410(0.00103751) overall-loss 0.85(0.89)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.02) Timer 69.58(69.69)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000190/000524 losses for all loc-loss 0.58(0.61) cls-loss 0.23(0.26) req-loss 0.00089246(0.00098672) overall-loss 0.81(0.87)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.14(69.69)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000200/000524 losses for all loc-loss 0.58(0.60) cls-loss 0.23(0.25) req-loss 0.00095791(0.00099506) overall-loss 0.81(0.85)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.81(69.68)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [1/30]000210/000524 losses for all loc-loss 0.55(0.59) cls-loss 0.24(0.24) req-loss 0.00086999(0.00091917) overall-loss 0.78(0.84)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.68(69.83)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000220/000524 losses for all loc-loss 0.65(0.59) cls-loss 0.24(0.24) req-loss 0.00108081(0.00094350) overall-loss 0.89(0.84)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.70(69.72)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000230/000524 losses for all loc-loss 0.54(0.58) cls-loss 0.23(0.24) req-loss 0.00093031(0.00091891) overall-loss 0.78(0.82)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.59(69.52)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000240/000524 losses for all loc-loss 0.57(0.57) cls-loss 0.25(0.24) req-loss 0.00086123(0.00092020) overall-loss 0.82(0.81)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.07(69.55)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000250/000524 losses for all loc-loss 0.57(0.56) cls-loss 0.22(0.23) req-loss 0.00096321(0.00092584) overall-loss 0.79(0.79)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.93(69.55)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000260/000524 losses for all loc-loss 0.50(0.55) cls-loss 0.23(0.23) req-loss 0.00069296(0.00089512) overall-loss 0.73(0.78)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.24(69.58)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000270/000524 losses for all loc-loss 0.51(0.54) cls-loss 0.21(0.23) req-loss 0.00100380(0.00087464) overall-loss 0.72(0.77)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.78(69.53)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000280/000524 losses for all loc-loss 0.52(0.53) cls-loss 0.22(0.22) req-loss 0.00078559(0.00087722) overall-loss 0.73(0.76)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.83(69.24)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000290/000524 losses for all loc-loss 0.64(0.54) cls-loss 0.24(0.22) req-loss 0.00088012(0.00085822) overall-loss 0.88(0.76)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.60(69.25)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000300/000524 losses for all loc-loss 0.51(0.53) cls-loss 0.20(0.22) req-loss 0.00100899(0.00084741) overall-loss 0.71(0.75)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.37(69.36)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000310/000524 losses for all loc-loss 0.51(0.53) cls-loss 0.20(0.21) req-loss 0.00087696(0.00086304) overall-loss 0.71(0.74)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.30(69.33)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000320/000524 losses for all loc-loss 0.46(0.51) cls-loss 0.19(0.21) req-loss 0.00084078(0.00086639) overall-loss 0.65(0.72)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.80(69.03)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000330/000524 losses for all loc-loss 0.47(0.50) cls-loss 0.18(0.21) req-loss 0.00081366(0.00083182) overall-loss 0.65(0.71)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.93(69.20)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000340/000524 losses for all loc-loss 0.48(0.51) cls-loss 0.21(0.20) req-loss 0.00093597(0.00082558) overall-loss 0.69(0.71)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.44(69.25)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000350/000524 losses for all loc-loss 0.47(0.50) cls-loss 0.21(0.20) req-loss 0.00071955(0.00080829) overall-loss 0.68(0.71)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.54(69.01)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000360/000524 losses for all loc-loss 0.52(0.50) cls-loss 0.20(0.20) req-loss 0.00083512(0.00081073) overall-loss 0.71(0.70)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.07(68.81)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000370/000524 losses for all loc-loss 0.47(0.50) cls-loss 0.19(0.20) req-loss 0.00067252(0.00079746) overall-loss 0.66(0.70)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.51(68.87)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000380/000524 losses for all loc-loss 0.51(0.49) cls-loss 0.20(0.20) req-loss 0.00076389(0.00077510) overall-loss 0.71(0.69)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 69.26(68.78)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000390/000524 losses for all loc-loss 0.53(0.48) cls-loss 0.21(0.20) req-loss 0.00074619(0.00079037) overall-loss 0.75(0.68)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.92(68.79)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000400/000524 losses for all loc-loss 0.48(0.48) cls-loss 0.19(0.19) req-loss 0.00068390(0.00075560) overall-loss 0.67(0.68)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.13(68.86)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [1/30]000410/000524 losses for all loc-loss 0.49(0.49) cls-loss 0.19(0.20) req-loss 0.00062782(0.00076099) overall-loss 0.69(0.69)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 71.51(69.03)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000420/000524 losses for all loc-loss 0.53(0.49) cls-loss 0.20(0.20) req-loss 0.00068361(0.00074098) overall-loss 0.73(0.68)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 69.29(68.88)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000430/000524 losses for all loc-loss 0.52(0.48) cls-loss 0.21(0.19) req-loss 0.00080794(0.00074582) overall-loss 0.72(0.67)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.03(68.70)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000440/000524 losses for all loc-loss 0.50(0.48) cls-loss 0.18(0.19) req-loss 0.00071490(0.00073561) overall-loss 0.68(0.67)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.13(68.56)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000450/000524 losses for all loc-loss 0.43(0.47) cls-loss 0.18(0.19) req-loss 0.00065744(0.00076713) overall-loss 0.61(0.66)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.69(68.50)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000460/000524 losses for all loc-loss 0.46(0.48) cls-loss 0.18(0.19) req-loss 0.00078273(0.00073057) overall-loss 0.64(0.67)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.34(68.46)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000470/000524 losses for all loc-loss 0.44(0.48) cls-loss 0.18(0.19) req-loss 0.00066841(0.00074360) overall-loss 0.62(0.67)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.63(68.65)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000480/000524 losses for all loc-loss 0.47(0.48) cls-loss 0.20(0.19) req-loss 0.00069988(0.00071757) overall-loss 0.67(0.67)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.27(68.75)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000490/000524 losses for all loc-loss 0.44(0.46) cls-loss 0.18(0.19) req-loss 0.00059521(0.00073812) overall-loss 0.63(0.65)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.41(68.58)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000500/000524 losses for all loc-loss 0.49(0.46) cls-loss 0.19(0.18) req-loss 0.00082105(0.00073685) overall-loss 0.68(0.65)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.17(68.64)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000510/000524 losses for all loc-loss 0.46(0.46) cls-loss 0.19(0.18) req-loss 0.00073040(0.00073466) overall-loss 0.66(0.64)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.70(68.75)\n",
      "[INFO: train.py:  355]: Iteration [1/30]000520/000524 losses for all loc-loss 0.50(0.45) cls-loss 0.20(0.18) req-loss 0.00067389(0.00070315) overall-loss 0.69(0.64)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.28(68.35)\n",
      "[INFO: train.py:  369]: Saving state, epoch:1\n",
      "[INFO: val.py:   41]: Validating at 1 number of samples:: 282\n",
      "[INFO: val.py:   82]: Forward Time 5.191\n",
      "[INFO: val.py:  115]: detections done: 20/282 time taken 49.985\n",
      "[INFO: val.py:  121]: NMS stuff Time 37.257\n",
      "[INFO: val.py:  123]: Evaluating detections for epoch number 1\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 60.445877\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 31.568405\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 13.47644\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 20.746523\n",
      "[INFO: train.py:  392]: agent_ness : 7503.0 : 21442 : 60.44587572838531\n",
      "[INFO: train.py:  394]: \n",
      "agent_ness MEANAP:::=> 60.44588\n",
      "[INFO: train.py:  392]: Ped : 2390.0 : 42996 : 57.2061506688879\n",
      "[INFO: train.py:  392]: Car : 1304.0 : 20417 : 49.69811587422848\n",
      "[INFO: train.py:  392]: Cyc : 782.0 : 33087 : 47.36394826166104\n",
      "[INFO: train.py:  392]: Mobike : 266.0 : 33745 : 35.036685404761705\n",
      "[INFO: train.py:  392]: MedVeh : 1251.0 : 22199 : 21.743486540332693\n",
      "[INFO: train.py:  392]: LarVeh : 95.0 : 24040 : 1.584544427214787\n",
      "[INFO: train.py:  392]: Bus : 235.0 : 26808 : 36.786280619436475\n",
      "[INFO: train.py:  392]: EmVeh : 1 : 37149 : 0.0\n",
      "[INFO: train.py:  392]: TL : 962.0 : 39194 : 58.03986243800948\n",
      "[INFO: train.py:  392]: OthTL : 218.0 : 36751 : 8.224961086164164\n",
      "[INFO: train.py:  394]: \n",
      "agent MEANAP:::=> 31.56841\n",
      "[INFO: train.py:  392]: Red : 790.0 : 55949 : 53.731008326052844\n",
      "[INFO: train.py:  392]: Amber : 54.0 : 49774 : 0.7338278703479728\n",
      "[INFO: train.py:  392]: Green : 336.0 : 59993 : 14.402862309263636\n",
      "[INFO: train.py:  392]: MovAway : 1824.0 : 24945 : 23.797434956272113\n",
      "[INFO: train.py:  392]: MovTow : 1781.0 : 27468 : 39.44298076572016\n",
      "[INFO: train.py:  392]: Mov : 229.0 : 39590 : 10.149419952185902\n",
      "[INFO: train.py:  392]: Brake : 154.0 : 19454 : 7.740779924813912\n",
      "[INFO: train.py:  392]: Stop : 2100.0 : 20514 : 33.78261895443216\n",
      "[INFO: train.py:  392]: IncatLft : 224.0 : 17768 : 19.45178176787805\n",
      "[INFO: train.py:  392]: IncatRht : 263.0 : 18050 : 9.775105638006917\n",
      "[INFO: train.py:  392]: HazLit : 126.0 : 20002 : 8.1127448723286\n",
      "[INFO: train.py:  392]: TurLft : 89.0 : 22296 : 1.6701073495212937\n",
      "[INFO: train.py:  392]: TurRht : 101.0 : 21656 : 5.571372961003475\n",
      "[INFO: train.py:  392]: Ovtak : 26.0 : 25889 : 1.128992947426954\n",
      "[INFO: train.py:  392]: Wait2X : 110.0 : 43160 : 1.0062948914609686\n",
      "[INFO: train.py:  392]: XingFmLft : 255.0 : 29074 : 9.847497724124112\n",
      "[INFO: train.py:  392]: XingFmRht : 144.0 : 27829 : 7.981801553204673\n",
      "[INFO: train.py:  392]: Xing : 32.0 : 40837 : 3.064958478184994\n",
      "[INFO: train.py:  392]: PushObj : 63.0 : 30974 : 4.660787523230598\n",
      "[INFO: train.py:  394]: \n",
      "action MEANAP:::=> 13.47644\n",
      "[INFO: train.py:  392]: VehLane : 1512.0 : 21248 : 46.677255886400395\n",
      "[INFO: train.py:  392]: OutgoLane : 266.0 : 21911 : 7.418353993922773\n",
      "[INFO: train.py:  392]: OutgoCycLane : 136.0 : 34918 : 4.505021636462027\n",
      "[INFO: train.py:  392]: IncomLane : 1386.0 : 21340 : 47.364537848974464\n",
      "[INFO: train.py:  392]: IncomCycLane : 108.0 : 30149 : 15.664810803464627\n",
      "[INFO: train.py:  392]: Pav : 266.0 : 47085 : 14.579190228991356\n",
      "[INFO: train.py:  392]: LftPav : 1052.0 : 43455 : 45.020401347633644\n",
      "[INFO: train.py:  392]: RhtPav : 910.0 : 46698 : 37.38199783385239\n",
      "[INFO: train.py:  392]: Jun : 1420.0 : 20559 : 27.47993866812582\n",
      "[INFO: train.py:  392]: xing : 21.0 : 29840 : 1.359151951700154\n",
      "[INFO: train.py:  392]: BusStop : 41.0 : 32975 : 1.507609933843569\n",
      "[INFO: train.py:  392]: parking : 1 : 29523 : 0.0\n",
      "[INFO: train.py:  394]: \n",
      "loc MEANAP:::=> 20.74652\n",
      "[INFO: train.py:  410]: \n",
      "Validation TIME::: 551.070\n",
      "\n",
      "\n",
      "LR at epoch 2 is [0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483, 0.0001196713164611488, 0.00023934263018324483]\n",
      "[INFO: train.py:  355]: Iteration [2/30]000010/000524 losses for all loc-loss 0.44(0.45) cls-loss 0.18(0.18) req-loss 0.00077277(0.00064761) overall-loss 0.63(0.63)\n",
      "[INFO: train.py:  365]: DataTime 0.00(47.67) Timer 68.90(116.15)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000020/000524 losses for all loc-loss 0.47(0.45) cls-loss 0.18(0.18) req-loss 0.00063306(0.00066517) overall-loss 0.65(0.64)\n",
      "[INFO: train.py:  365]: DataTime 0.01(28.54) Timer 69.92(96.99)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000030/000524 losses for all loc-loss 0.44(0.45) cls-loss 0.17(0.18) req-loss 0.00072926(0.00066767) overall-loss 0.61(0.63)\n",
      "[INFO: train.py:  365]: DataTime 0.01(17.09) Timer 70.33(85.62)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000040/000524 losses for all loc-loss 0.47(0.45) cls-loss 0.19(0.18) req-loss 0.00066864(0.00068168) overall-loss 0.66(0.63)\n",
      "[INFO: train.py:  365]: DataTime 0.01(10.24) Timer 67.78(78.68)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000050/000524 losses for all loc-loss 0.42(0.45) cls-loss 0.17(0.18) req-loss 0.00069189(0.00068304) overall-loss 0.60(0.63)\n",
      "[INFO: train.py:  365]: DataTime 0.01(6.13) Timer 67.96(74.48)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000060/000524 losses for all loc-loss 0.47(0.45) cls-loss 0.18(0.18) req-loss 0.00070947(0.00067972) overall-loss 0.65(0.63)\n",
      "[INFO: train.py:  365]: DataTime 0.01(3.67) Timer 68.76(72.04)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000070/000524 losses for all loc-loss 0.48(0.45) cls-loss 0.19(0.18) req-loss 0.00059170(0.00069388) overall-loss 0.67(0.62)\n",
      "[INFO: train.py:  365]: DataTime 0.01(2.20) Timer 68.41(70.69)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000080/000524 losses for all loc-loss 0.47(0.44) cls-loss 0.16(0.17) req-loss 0.00064832(0.00066174) overall-loss 0.63(0.62)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.32) Timer 68.45(69.78)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000090/000524 losses for all loc-loss 0.47(0.43) cls-loss 0.17(0.17) req-loss 0.00056410(0.00066873) overall-loss 0.64(0.61)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.79) Timer 68.19(69.22)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000100/000524 losses for all loc-loss 0.44(0.43) cls-loss 0.17(0.17) req-loss 0.00065845(0.00065355) overall-loss 0.61(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.48) Timer 69.78(68.91)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000110/000524 losses for all loc-loss 0.40(0.44) cls-loss 0.16(0.17) req-loss 0.00066137(0.00065555) overall-loss 0.56(0.61)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.29) Timer 68.55(68.77)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000120/000524 losses for all loc-loss 0.37(0.43) cls-loss 0.14(0.17) req-loss 0.00078183(0.00064703) overall-loss 0.52(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.18) Timer 67.64(68.63)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000130/000524 losses for all loc-loss 0.47(0.44) cls-loss 0.20(0.17) req-loss 0.00056344(0.00063044) overall-loss 0.67(0.62)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.11) Timer 66.74(68.35)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000140/000524 losses for all loc-loss 0.42(0.44) cls-loss 0.17(0.17) req-loss 0.00062567(0.00064720) overall-loss 0.58(0.61)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.07) Timer 69.11(68.43)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000150/000524 losses for all loc-loss 0.39(0.44) cls-loss 0.17(0.17) req-loss 0.00064111(0.00066102) overall-loss 0.56(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.04) Timer 68.41(68.46)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000160/000524 losses for all loc-loss 0.42(0.43) cls-loss 0.17(0.17) req-loss 0.00065154(0.00064967) overall-loss 0.59(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.03) Timer 68.02(68.30)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000170/000524 losses for all loc-loss 0.45(0.43) cls-loss 0.21(0.17) req-loss 0.00066090(0.00063659) overall-loss 0.66(0.61)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.02) Timer 68.36(68.25)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000180/000524 losses for all loc-loss 0.46(0.43) cls-loss 0.19(0.17) req-loss 0.00058836(0.00062076) overall-loss 0.65(0.61)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 69.16(68.05)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000190/000524 losses for all loc-loss 0.48(0.43) cls-loss 0.18(0.17) req-loss 0.00073737(0.00063941) overall-loss 0.66(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 66.95(68.19)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000200/000524 losses for all loc-loss 0.41(0.43) cls-loss 0.16(0.17) req-loss 0.00057560(0.00063966) overall-loss 0.57(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.49(68.33)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [2/30]000210/000524 losses for all loc-loss 0.42(0.43) cls-loss 0.18(0.17) req-loss 0.00066656(0.00061224) overall-loss 0.60(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.01(68.34)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000220/000524 losses for all loc-loss 0.44(0.43) cls-loss 0.17(0.17) req-loss 0.00057530(0.00062663) overall-loss 0.61(0.60)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.62(68.34)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000230/000524 losses for all loc-loss 0.41(0.43) cls-loss 0.16(0.17) req-loss 0.00053984(0.00060272) overall-loss 0.57(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.27(68.24)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000240/000524 losses for all loc-loss 0.43(0.42) cls-loss 0.16(0.16) req-loss 0.00064474(0.00061250) overall-loss 0.59(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.09(68.14)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000250/000524 losses for all loc-loss 0.43(0.42) cls-loss 0.17(0.17) req-loss 0.00053519(0.00059703) overall-loss 0.60(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.77(68.18)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000260/000524 losses for all loc-loss 0.44(0.42) cls-loss 0.17(0.17) req-loss 0.00066018(0.00062783) overall-loss 0.61(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.30(68.21)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000270/000524 losses for all loc-loss 0.44(0.42) cls-loss 0.16(0.17) req-loss 0.00051099(0.00061977) overall-loss 0.59(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.77(68.03)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000280/000524 losses for all loc-loss 0.46(0.42) cls-loss 0.17(0.16) req-loss 0.00071514(0.00061817) overall-loss 0.63(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 66.53(67.95)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000290/000524 losses for all loc-loss 0.48(0.43) cls-loss 0.18(0.17) req-loss 0.00048745(0.00061605) overall-loss 0.67(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.61(67.97)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000300/000524 losses for all loc-loss 0.46(0.42) cls-loss 0.16(0.16) req-loss 0.00063515(0.00063338) overall-loss 0.62(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.67(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000310/000524 losses for all loc-loss 0.47(0.43) cls-loss 0.16(0.16) req-loss 0.00053740(0.00059626) overall-loss 0.63(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.65(68.25)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000320/000524 losses for all loc-loss 0.45(0.42) cls-loss 0.18(0.16) req-loss 0.00056469(0.00060275) overall-loss 0.63(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.90(68.16)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000330/000524 losses for all loc-loss 0.43(0.42) cls-loss 0.17(0.17) req-loss 0.00068682(0.00060422) overall-loss 0.60(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.75(68.21)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000340/000524 losses for all loc-loss 0.40(0.42) cls-loss 0.15(0.16) req-loss 0.00049353(0.00059570) overall-loss 0.55(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.40(68.13)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000350/000524 losses for all loc-loss 0.39(0.41) cls-loss 0.14(0.16) req-loss 0.00075448(0.00061757) overall-loss 0.54(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.43(68.11)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000360/000524 losses for all loc-loss 0.40(0.41) cls-loss 0.17(0.16) req-loss 0.00058639(0.00061165) overall-loss 0.58(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.94(68.08)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000370/000524 losses for all loc-loss 0.45(0.41) cls-loss 0.16(0.16) req-loss 0.00059706(0.00060110) overall-loss 0.61(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.20(67.96)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000380/000524 losses for all loc-loss 0.40(0.42) cls-loss 0.14(0.16) req-loss 0.00055438(0.00057348) overall-loss 0.55(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.22(68.14)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000390/000524 losses for all loc-loss 0.46(0.42) cls-loss 0.16(0.16) req-loss 0.00053799(0.00055504) overall-loss 0.62(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.50(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000400/000524 losses for all loc-loss 0.43(0.42) cls-loss 0.17(0.16) req-loss 0.00056183(0.00059197) overall-loss 0.60(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.83(68.16)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [2/30]000410/000524 losses for all loc-loss 0.51(0.42) cls-loss 0.18(0.16) req-loss 0.00058132(0.00057785) overall-loss 0.69(0.59)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 70.25(68.18)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000420/000524 losses for all loc-loss 0.43(0.42) cls-loss 0.14(0.16) req-loss 0.00059867(0.00060283) overall-loss 0.57(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.42(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000430/000524 losses for all loc-loss 0.37(0.41) cls-loss 0.16(0.16) req-loss 0.00051308(0.00058163) overall-loss 0.53(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.17(68.46)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000440/000524 losses for all loc-loss 0.47(0.41) cls-loss 0.18(0.16) req-loss 0.00058997(0.00056008) overall-loss 0.65(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.55(68.18)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000450/000524 losses for all loc-loss 0.44(0.42) cls-loss 0.16(0.16) req-loss 0.00053895(0.00056657) overall-loss 0.60(0.58)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.66(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000460/000524 losses for all loc-loss 0.33(0.41) cls-loss 0.13(0.16) req-loss 0.00058049(0.00057461) overall-loss 0.45(0.57)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.65(68.36)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000470/000524 losses for all loc-loss 0.39(0.41) cls-loss 0.15(0.15) req-loss 0.00050163(0.00058517) overall-loss 0.54(0.56)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.25(68.33)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000480/000524 losses for all loc-loss 0.44(0.41) cls-loss 0.19(0.15) req-loss 0.00052613(0.00055423) overall-loss 0.63(0.56)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.66(68.30)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000490/000524 losses for all loc-loss 0.44(0.40) cls-loss 0.17(0.15) req-loss 0.00053591(0.00056596) overall-loss 0.61(0.56)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.98(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000500/000524 losses for all loc-loss 0.45(0.41) cls-loss 0.16(0.15) req-loss 0.00051904(0.00056118) overall-loss 0.61(0.56)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.35(68.23)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000510/000524 losses for all loc-loss 0.37(0.40) cls-loss 0.14(0.15) req-loss 0.00048494(0.00057370) overall-loss 0.51(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.45(68.11)\n",
      "[INFO: train.py:  355]: Iteration [2/30]000520/000524 losses for all loc-loss 0.40(0.40) cls-loss 0.14(0.15) req-loss 0.00048923(0.00053844) overall-loss 0.55(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.21(68.11)\n",
      "[INFO: train.py:  369]: Saving state, epoch:2\n",
      "[INFO: val.py:   41]: Validating at 2 number of samples:: 282\n",
      "[INFO: val.py:   82]: Forward Time 5.188\n",
      "[INFO: val.py:  115]: detections done: 20/282 time taken 54.743\n",
      "[INFO: val.py:  121]: NMS stuff Time 40.711\n",
      "[INFO: val.py:  123]: Evaluating detections for epoch number 2\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 65.97783\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 41.304802\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 19.653135\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 28.98017\n",
      "[INFO: train.py:  392]: agent_ness : 7503.0 : 21373 : 65.97783133360493\n",
      "[INFO: train.py:  394]: \n",
      "agent_ness MEANAP:::=> 65.97783\n",
      "[INFO: train.py:  392]: Ped : 2390.0 : 45446 : 66.00739043709108\n",
      "[INFO: train.py:  392]: Car : 1304.0 : 21776 : 60.184996252950995\n",
      "[INFO: train.py:  392]: Cyc : 782.0 : 34123 : 61.65121616762907\n",
      "[INFO: train.py:  392]: Mobike : 266.0 : 38604 : 69.62986105024368\n",
      "[INFO: train.py:  392]: MedVeh : 1251.0 : 21051 : 32.32276875246256\n",
      "[INFO: train.py:  392]: LarVeh : 95.0 : 22776 : 1.427070034317112\n",
      "[INFO: train.py:  392]: Bus : 235.0 : 24093 : 48.44130703848418\n",
      "[INFO: train.py:  392]: EmVeh : 1 : 38642 : 0.0\n",
      "[INFO: train.py:  392]: TL : 962.0 : 44834 : 67.77182058253722\n",
      "[INFO: train.py:  392]: OthTL : 218.0 : 39104 : 5.61161032976026\n",
      "[INFO: train.py:  394]: \n",
      "agent MEANAP:::=> 41.30480\n",
      "[INFO: train.py:  392]: Red : 790.0 : 60484 : 59.52031282052695\n",
      "[INFO: train.py:  392]: Amber : 54.0 : 48201 : 1.2358908032195755\n",
      "[INFO: train.py:  392]: Green : 336.0 : 59018 : 38.369775431479844\n",
      "[INFO: train.py:  392]: MovAway : 1824.0 : 25334 : 31.33570194875666\n",
      "[INFO: train.py:  392]: MovTow : 1781.0 : 26327 : 44.28028939733697\n",
      "[INFO: train.py:  392]: Mov : 229.0 : 38555 : 35.52556859874906\n",
      "[INFO: train.py:  392]: Brake : 154.0 : 16959 : 8.430597817948795\n",
      "[INFO: train.py:  392]: Stop : 2100.0 : 19931 : 45.43305352296266\n",
      "[INFO: train.py:  392]: IncatLft : 224.0 : 14697 : 12.921897405309867\n",
      "[INFO: train.py:  392]: IncatRht : 263.0 : 16926 : 5.32070543268212\n",
      "[INFO: train.py:  392]: HazLit : 126.0 : 18379 : 6.507858760960003\n",
      "[INFO: train.py:  392]: TurLft : 89.0 : 19322 : 2.631292928708177\n",
      "[INFO: train.py:  392]: TurRht : 101.0 : 19581 : 8.496975739312102\n",
      "[INFO: train.py:  392]: Ovtak : 26.0 : 24883 : 0.4484713702410245\n",
      "[INFO: train.py:  392]: Wait2X : 110.0 : 44545 : 2.164671087068977\n",
      "[INFO: train.py:  392]: XingFmLft : 255.0 : 27208 : 28.329702729735896\n",
      "[INFO: train.py:  392]: XingFmRht : 144.0 : 28035 : 25.483625421632322\n",
      "[INFO: train.py:  392]: Xing : 32.0 : 32485 : 2.3078633496114542\n",
      "[INFO: train.py:  392]: PushObj : 63.0 : 26535 : 14.665338066862601\n",
      "[INFO: train.py:  394]: \n",
      "action MEANAP:::=> 19.65314\n",
      "[INFO: train.py:  392]: VehLane : 1512.0 : 20669 : 53.03284804623589\n",
      "[INFO: train.py:  392]: OutgoLane : 266.0 : 22721 : 31.533565466171957\n",
      "[INFO: train.py:  392]: OutgoCycLane : 136.0 : 35167 : 20.901857575528\n",
      "[INFO: train.py:  392]: IncomLane : 1386.0 : 19874 : 62.18552585990167\n",
      "[INFO: train.py:  392]: IncomCycLane : 108.0 : 29889 : 16.090487167377347\n",
      "[INFO: train.py:  392]: Pav : 266.0 : 41589 : 30.07711375405886\n",
      "[INFO: train.py:  392]: LftPav : 1052.0 : 41474 : 53.966294021477346\n",
      "[INFO: train.py:  392]: RhtPav : 910.0 : 40361 : 44.80778976435853\n",
      "[INFO: train.py:  392]: Jun : 1420.0 : 19803 : 29.943942346511875\n",
      "[INFO: train.py:  392]: xing : 21.0 : 38800 : 3.0673873664055917\n",
      "[INFO: train.py:  392]: BusStop : 41.0 : 31283 : 2.155230049002111\n",
      "[INFO: train.py:  392]: parking : 1 : 37648 : 0.0\n",
      "[INFO: train.py:  394]: \n",
      "loc MEANAP:::=> 28.98017\n",
      "[INFO: train.py:  410]: \n",
      "Validation TIME::: 601.671\n",
      "\n",
      "\n",
      "LR at epoch 3 is [0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558, 0.00011868886697022783, 0.00023737772301425558]\n",
      "[INFO: train.py:  355]: Iteration [3/30]000010/000524 losses for all loc-loss 0.45(0.39) cls-loss 0.15(0.15) req-loss 0.00051677(0.00059561) overall-loss 0.60(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(50.66) Timer 68.12(118.28)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000020/000524 losses for all loc-loss 0.42(0.39) cls-loss 0.15(0.15) req-loss 0.00050068(0.00056782) overall-loss 0.57(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(30.33) Timer 67.74(98.04)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000030/000524 losses for all loc-loss 0.41(0.39) cls-loss 0.16(0.15) req-loss 0.00052094(0.00056704) overall-loss 0.56(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(18.16) Timer 67.80(85.95)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000040/000524 losses for all loc-loss 0.39(0.39) cls-loss 0.16(0.15) req-loss 0.00066626(0.00055740) overall-loss 0.55(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(10.88) Timer 66.94(78.66)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000050/000524 losses for all loc-loss 0.41(0.39) cls-loss 0.18(0.15) req-loss 0.00049472(0.00055762) overall-loss 0.59(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(6.52) Timer 67.75(74.37)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000060/000524 losses for all loc-loss 0.39(0.39) cls-loss 0.15(0.15) req-loss 0.00054908(0.00056255) overall-loss 0.54(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(3.91) Timer 68.86(71.84)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000070/000524 losses for all loc-loss 0.46(0.40) cls-loss 0.18(0.15) req-loss 0.00050384(0.00053715) overall-loss 0.64(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(2.34) Timer 67.90(70.27)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000080/000524 losses for all loc-loss 0.44(0.39) cls-loss 0.16(0.15) req-loss 0.00059712(0.00054175) overall-loss 0.60(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.40) Timer 69.24(69.60)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000090/000524 losses for all loc-loss 0.35(0.39) cls-loss 0.14(0.15) req-loss 0.00052565(0.00055252) overall-loss 0.49(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.84) Timer 67.97(69.12)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000100/000524 losses for all loc-loss 0.34(0.39) cls-loss 0.13(0.15) req-loss 0.00060022(0.00054043) overall-loss 0.47(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.51) Timer 67.80(68.70)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000110/000524 losses for all loc-loss 0.42(0.39) cls-loss 0.16(0.15) req-loss 0.00052500(0.00054112) overall-loss 0.59(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.31) Timer 68.13(68.47)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000120/000524 losses for all loc-loss 0.36(0.38) cls-loss 0.15(0.15) req-loss 0.00050157(0.00053477) overall-loss 0.51(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.19) Timer 68.45(68.27)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000130/000524 losses for all loc-loss 0.33(0.38) cls-loss 0.16(0.15) req-loss 0.00055605(0.00052968) overall-loss 0.48(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.12) Timer 67.35(68.22)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000140/000524 losses for all loc-loss 0.41(0.39) cls-loss 0.15(0.15) req-loss 0.00049031(0.00052832) overall-loss 0.56(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.07) Timer 68.52(68.13)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000150/000524 losses for all loc-loss 0.42(0.39) cls-loss 0.13(0.15) req-loss 0.00063419(0.00054577) overall-loss 0.55(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.05) Timer 68.13(68.24)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000160/000524 losses for all loc-loss 0.41(0.39) cls-loss 0.18(0.15) req-loss 0.00050837(0.00054870) overall-loss 0.59(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.03) Timer 68.47(68.15)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000170/000524 losses for all loc-loss 0.38(0.39) cls-loss 0.15(0.15) req-loss 0.00053930(0.00055361) overall-loss 0.53(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.02) Timer 68.05(68.11)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000180/000524 losses for all loc-loss 0.42(0.39) cls-loss 0.16(0.15) req-loss 0.00060385(0.00054907) overall-loss 0.57(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.02) Timer 69.13(68.15)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000190/000524 losses for all loc-loss 0.38(0.39) cls-loss 0.14(0.15) req-loss 0.00053936(0.00052792) overall-loss 0.53(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.13(68.05)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000200/000524 losses for all loc-loss 0.34(0.38) cls-loss 0.13(0.15) req-loss 0.00057328(0.00054689) overall-loss 0.46(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.83(68.16)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [3/30]000210/000524 losses for all loc-loss 0.44(0.39) cls-loss 0.15(0.15) req-loss 0.00046492(0.00052077) overall-loss 0.59(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.09(68.18)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000220/000524 losses for all loc-loss 0.38(0.39) cls-loss 0.15(0.15) req-loss 0.00059634(0.00053900) overall-loss 0.53(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.00(68.18)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000230/000524 losses for all loc-loss 0.48(0.40) cls-loss 0.16(0.15) req-loss 0.00050992(0.00053706) overall-loss 0.64(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.69(68.36)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000240/000524 losses for all loc-loss 0.41(0.40) cls-loss 0.14(0.15) req-loss 0.00054592(0.00053732) overall-loss 0.55(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.08(68.26)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000250/000524 losses for all loc-loss 0.33(0.39) cls-loss 0.12(0.15) req-loss 0.00057352(0.00053085) overall-loss 0.45(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.92(68.30)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000260/000524 losses for all loc-loss 0.37(0.39) cls-loss 0.14(0.15) req-loss 0.00043499(0.00051716) overall-loss 0.52(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.30(68.23)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000270/000524 losses for all loc-loss 0.37(0.38) cls-loss 0.14(0.15) req-loss 0.00056422(0.00052763) overall-loss 0.51(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.40(68.09)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000280/000524 losses for all loc-loss 0.40(0.38) cls-loss 0.14(0.15) req-loss 0.00062168(0.00055512) overall-loss 0.54(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.37(68.07)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000290/000524 losses for all loc-loss 0.43(0.39) cls-loss 0.15(0.15) req-loss 0.00046480(0.00053615) overall-loss 0.58(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.59(68.05)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000300/000524 losses for all loc-loss 0.38(0.39) cls-loss 0.17(0.15) req-loss 0.00058538(0.00053451) overall-loss 0.55(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.38(68.01)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000310/000524 losses for all loc-loss 0.37(0.39) cls-loss 0.14(0.15) req-loss 0.00049424(0.00053979) overall-loss 0.51(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.17(68.18)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000320/000524 losses for all loc-loss 0.45(0.40) cls-loss 0.17(0.15) req-loss 0.00065529(0.00053937) overall-loss 0.62(0.55)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.56(68.19)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000330/000524 losses for all loc-loss 0.38(0.39) cls-loss 0.14(0.15) req-loss 0.00054622(0.00053375) overall-loss 0.52(0.54)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.21(68.15)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000340/000524 losses for all loc-loss 0.30(0.38) cls-loss 0.11(0.14) req-loss 0.00051284(0.00053212) overall-loss 0.42(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 66.34(67.99)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000350/000524 losses for all loc-loss 0.38(0.38) cls-loss 0.14(0.14) req-loss 0.00048721(0.00052441) overall-loss 0.52(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.18(68.12)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000360/000524 losses for all loc-loss 0.34(0.38) cls-loss 0.13(0.14) req-loss 0.00049430(0.00049165) overall-loss 0.47(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.69(68.08)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000370/000524 losses for all loc-loss 0.39(0.37) cls-loss 0.15(0.14) req-loss 0.00057751(0.00050084) overall-loss 0.54(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.71(68.05)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000380/000524 losses for all loc-loss 0.38(0.37) cls-loss 0.14(0.14) req-loss 0.00042462(0.00050367) overall-loss 0.51(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.33(67.98)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000390/000524 losses for all loc-loss 0.39(0.38) cls-loss 0.14(0.14) req-loss 0.00049591(0.00048389) overall-loss 0.53(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 67.85(67.93)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000400/000524 losses for all loc-loss 0.37(0.38) cls-loss 0.14(0.14) req-loss 0.00054681(0.00049473) overall-loss 0.51(0.53)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.61(67.97)\n",
      "[INFO: train.py:  368]: resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1-h3x3x3-10-05-19-50-33x\n",
      "[INFO: train.py:  355]: Iteration [3/30]000410/000524 losses for all loc-loss 0.42(0.38) cls-loss 0.16(0.14) req-loss 0.00051135(0.00050087) overall-loss 0.58(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.54(67.99)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000420/000524 losses for all loc-loss 0.39(0.38) cls-loss 0.16(0.14) req-loss 0.00049329(0.00050793) overall-loss 0.54(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.09(67.97)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000430/000524 losses for all loc-loss 0.39(0.38) cls-loss 0.15(0.14) req-loss 0.00046867(0.00049829) overall-loss 0.54(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 66.41(67.93)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000440/000524 losses for all loc-loss 0.35(0.37) cls-loss 0.14(0.14) req-loss 0.00048333(0.00049335) overall-loss 0.49(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.02(67.99)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000450/000524 losses for all loc-loss 0.39(0.38) cls-loss 0.15(0.14) req-loss 0.00047576(0.00049781) overall-loss 0.54(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.18(68.04)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000460/000524 losses for all loc-loss 0.33(0.37) cls-loss 0.13(0.14) req-loss 0.00050110(0.00051002) overall-loss 0.46(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.82(68.14)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000470/000524 losses for all loc-loss 0.37(0.37) cls-loss 0.13(0.14) req-loss 0.00051385(0.00049541) overall-loss 0.50(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.23(68.08)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000480/000524 losses for all loc-loss 0.38(0.37) cls-loss 0.15(0.14) req-loss 0.00044626(0.00050475) overall-loss 0.53(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.43(68.10)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000490/000524 losses for all loc-loss 0.33(0.37) cls-loss 0.13(0.14) req-loss 0.00057113(0.00050455) overall-loss 0.46(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 68.13(68.03)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000500/000524 losses for all loc-loss 0.42(0.38) cls-loss 0.15(0.14) req-loss 0.00049984(0.00048534) overall-loss 0.57(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.01) Timer 69.35(68.13)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000510/000524 losses for all loc-loss 0.33(0.37) cls-loss 0.14(0.14) req-loss 0.00045377(0.00050254) overall-loss 0.47(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 68.15(68.05)\n",
      "[INFO: train.py:  355]: Iteration [3/30]000520/000524 losses for all loc-loss 0.40(0.38) cls-loss 0.17(0.14) req-loss 0.00053221(0.00048875) overall-loss 0.56(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.00(0.01) Timer 67.36(68.01)\n",
      "[INFO: train.py:  369]: Saving state, epoch:3\n",
      "[INFO: val.py:   41]: Validating at 3 number of samples:: 282\n",
      "[INFO: val.py:   82]: Forward Time 5.192\n",
      "[INFO: val.py:  115]: detections done: 20/282 time taken 53.933\n",
      "[INFO: val.py:  121]: NMS stuff Time 41.505\n",
      "[INFO: val.py:  123]: Evaluating detections for epoch number 3\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 69.196655\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 46.10921\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 21.802376\n",
      "[INFO: evaluation.py:  107]: Evaluating for 2256 frames\n",
      "[INFO: evaluation.py:  171]: mean ap 33.785137\n",
      "[INFO: train.py:  392]: agent_ness : 7503.0 : 21595 : 69.19665851829804\n",
      "[INFO: train.py:  394]: \n",
      "agent_ness MEANAP:::=> 69.19666\n",
      "[INFO: train.py:  392]: Ped : 2390.0 : 44324 : 65.56053923587682\n",
      "[INFO: train.py:  392]: Car : 1304.0 : 24651 : 63.39669679782895\n",
      "[INFO: train.py:  392]: Cyc : 782.0 : 32908 : 54.722479085339124\n",
      "[INFO: train.py:  392]: Mobike : 266.0 : 43979 : 70.30352456903826\n",
      "[INFO: train.py:  392]: MedVeh : 1251.0 : 26061 : 37.38757957479657\n",
      "[INFO: train.py:  392]: LarVeh : 95.0 : 27677 : 2.0898295680205985\n",
      "[INFO: train.py:  392]: Bus : 235.0 : 28779 : 56.54659998336831\n",
      "[INFO: train.py:  392]: EmVeh : 1 : 43004 : 0.0\n",
      "[INFO: train.py:  392]: TL : 962.0 : 45108 : 74.72974696385101\n",
      "[INFO: train.py:  392]: OthTL : 218.0 : 46862 : 36.35510629859172\n",
      "[INFO: train.py:  394]: \n",
      "agent MEANAP:::=> 46.10921\n",
      "[INFO: train.py:  392]: Red : 790.0 : 61387 : 63.90474862747346\n",
      "[INFO: train.py:  392]: Amber : 54.0 : 41207 : 1.6418875892702438\n",
      "[INFO: train.py:  392]: Green : 336.0 : 61853 : 46.16893013265209\n",
      "[INFO: train.py:  392]: MovAway : 1824.0 : 26300 : 37.18329332971006\n",
      "[INFO: train.py:  392]: MovTow : 1781.0 : 26610 : 48.509791777341825\n",
      "[INFO: train.py:  392]: Mov : 229.0 : 33432 : 39.24948101851601\n",
      "[INFO: train.py:  392]: Brake : 154.0 : 18512 : 7.482062957151013\n",
      "[INFO: train.py:  392]: Stop : 2100.0 : 22304 : 49.91563611466387\n",
      "[INFO: train.py:  392]: IncatLft : 224.0 : 14724 : 11.119995486588618\n",
      "[INFO: train.py:  392]: IncatRht : 263.0 : 15629 : 9.695010693333693\n",
      "[INFO: train.py:  392]: HazLit : 126.0 : 16319 : 6.255625232425059\n",
      "[INFO: train.py:  392]: TurLft : 89.0 : 20344 : 7.278833176834041\n",
      "[INFO: train.py:  392]: TurRht : 101.0 : 21839 : 17.424258899553408\n",
      "[INFO: train.py:  392]: Ovtak : 26.0 : 18252 : 0.5659018883098865\n",
      "[INFO: train.py:  392]: Wait2X : 110.0 : 49899 : 2.437041862805296\n",
      "[INFO: train.py:  392]: XingFmLft : 255.0 : 23835 : 24.849258960582876\n",
      "[INFO: train.py:  392]: XingFmRht : 144.0 : 25230 : 25.608999709909057\n",
      "[INFO: train.py:  392]: Xing : 32.0 : 34997 : 2.4168339704291406\n",
      "[INFO: train.py:  392]: PushObj : 63.0 : 24555 : 12.537527915133747\n",
      "[INFO: train.py:  394]: \n",
      "action MEANAP:::=> 21.80238\n",
      "[INFO: train.py:  392]: VehLane : 1512.0 : 22513 : 58.28411417048576\n",
      "[INFO: train.py:  392]: OutgoLane : 266.0 : 23088 : 21.185477007988236\n",
      "[INFO: train.py:  392]: OutgoCycLane : 136.0 : 37425 : 24.298874074429115\n",
      "[INFO: train.py:  392]: IncomLane : 1386.0 : 23268 : 65.33166173195518\n",
      "[INFO: train.py:  392]: IncomCycLane : 108.0 : 38773 : 21.787432442791147\n",
      "[INFO: train.py:  392]: Pav : 266.0 : 45013 : 35.51267211711223\n",
      "[INFO: train.py:  392]: LftPav : 1052.0 : 40837 : 57.37680831513029\n",
      "[INFO: train.py:  392]: RhtPav : 910.0 : 44857 : 44.9257538591016\n",
      "[INFO: train.py:  392]: Jun : 1420.0 : 19242 : 40.24682976838552\n",
      "[INFO: train.py:  392]: xing : 21.0 : 42982 : 34.402245099113586\n",
      "[INFO: train.py:  392]: BusStop : 41.0 : 33606 : 2.069806965702134\n",
      "[INFO: train.py:  392]: parking : 1 : 36825 : 0.0\n",
      "[INFO: train.py:  394]: \n",
      "loc MEANAP:::=> 33.78514\n",
      "[INFO: train.py:  410]: \n",
      "Validation TIME::: 647.326\n",
      "\n",
      "\n",
      "LR at epoch 4 is [0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907, 0.0001170634154494509, 0.00023412680642715907]\n",
      "[INFO: train.py:  355]: Iteration [4/30]000010/000524 losses for all loc-loss 0.35(0.35) cls-loss 0.16(0.15) req-loss 0.00040805(0.00051611) overall-loss 0.51(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(39.90) Timer 67.64(107.39)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000020/000524 losses for all loc-loss 0.37(0.36) cls-loss 0.14(0.14) req-loss 0.00051218(0.00050182) overall-loss 0.51(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(23.89) Timer 68.22(91.42)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000030/000524 losses for all loc-loss 0.36(0.36) cls-loss 0.13(0.14) req-loss 0.00044060(0.00049038) overall-loss 0.49(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(14.31) Timer 69.07(82.10)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000040/000524 losses for all loc-loss 0.37(0.36) cls-loss 0.14(0.14) req-loss 0.00050062(0.00049123) overall-loss 0.51(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(8.57) Timer 68.73(76.48)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000050/000524 losses for all loc-loss 0.31(0.36) cls-loss 0.13(0.14) req-loss 0.00052053(0.00050226) overall-loss 0.44(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(5.13) Timer 68.86(73.14)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000060/000524 losses for all loc-loss 0.33(0.36) cls-loss 0.13(0.14) req-loss 0.00042397(0.00049423) overall-loss 0.46(0.49)\n",
      "[INFO: train.py:  365]: DataTime 0.01(3.08) Timer 69.06(71.19)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000070/000524 losses for all loc-loss 0.34(0.36) cls-loss 0.13(0.14) req-loss 0.00046837(0.00046991) overall-loss 0.46(0.50)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.85) Timer 67.26(69.79)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000080/000524 losses for all loc-loss 0.38(0.37) cls-loss 0.16(0.14) req-loss 0.00050849(0.00048806) overall-loss 0.53(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(1.11) Timer 68.93(69.19)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000090/000524 losses for all loc-loss 0.36(0.37) cls-loss 0.13(0.14) req-loss 0.00052238(0.00047889) overall-loss 0.48(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.67) Timer 68.39(68.79)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000100/000524 losses for all loc-loss 0.38(0.37) cls-loss 0.14(0.14) req-loss 0.00049770(0.00048722) overall-loss 0.53(0.51)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.40) Timer 69.13(68.50)\n",
      "[INFO: train.py:  355]: Iteration [4/30]000110/000524 losses for all loc-loss 0.35(0.38) cls-loss 0.14(0.14) req-loss 0.00045699(0.00048334) overall-loss 0.49(0.52)\n",
      "[INFO: train.py:  365]: DataTime 0.01(0.24) Timer 68.29(68.22)\n"
     ]
    }
   ],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "! python main.py --TASK=2 --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task1.pth\" --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE/\" --MODE=\"train\" --LOGIC=\"Lukasiewicz\" --VAL_STEP=1 --LR=0.00012 --MAX_EPOCHS=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming the training\n",
    "To resume the training of a model, provide the path to the directory containing the checkpoint from which the experiment should be resumed in the `EXP_NAME` argument.\n",
    "If the last completed epoch was number 15, the training can be resumed by specifying `--RESUME=15` in the training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 13, in <module>\n",
      "    from models.retinanet import build_retinanet\n",
      "  File \"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/models/retinanet.py\", line 19, in <module>\n",
      "    from models.backbone_models import backbone_models\n",
      "  File \"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/models/backbone_models.py\", line 1, in <module>\n",
      "    from models.resnetFPN import resnetfpn\n",
      "  File \"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/models/resnetFPN.py\", line 8, in <module>\n",
      "    from models.backbones import swin_transformer\n",
      "  File \"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/models/backbones/swin_transformer.py\", line 6, in <module>\n",
      "    from timm.models.layers import DropPath, trunc_normal_\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/timm/__init__.py\", line 3, in <module>\n",
      "    from .models import create_model, list_models, list_pretrained, is_model, list_modules, model_entrypoint, \\\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/timm/models/__init__.py\", line 48, in <module>\n",
      "    from .repvit import *\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 640, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "EXP_NAME=\"../experiments/task2/road/logic-ssl_cache_Lukasiewicz_10.0/resnet50RCGRU512-Pkinetics-b4s8x1x1-roadt1-h3x3x3-05-01-01-01-01x/\"\n",
    "\n",
    "! python main.py {TASK} {DATA_ROOT} {EXPDIR}/{EXP_ID}/ {MODEL_PATH} --MODE=\"train\" --VAL_STEP=2 --LR=0.0041 --MAX_EPOCHS=30 --MILESTONES=20,25 --LOGIC={LOGIC} --EXP_NAME={EXP_NAME} --RESUME=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Similarly to resuming the training, the experiment's path must be provided in the `EXP_NAME` argument.\n",
    "Additionally, the `MODE` argument must be set to \"gen_dets\" and `TEST_SUBSETS` to \"test\".\n",
    "\n",
    "To evaluate the model at epoch 130, provide `--EVAL_EPOCHS=130` in the command line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directories are::\n",
      "LOAD::>  /root/autodl-tmp/road-dataset-master/ \n",
      "SAVE::>  /root/autodl-tmp/road-dataset-master/SAVE2/\n",
      "Your model will be initialized using /root/autodl-tmp/road-dataset-master/SAVE2//model_000020.pth\n",
      "Do not create a new experiment dir, instead use /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  264]: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
      "[GCC 7.5.0]\n",
      "[INFO: datasets.py:  400]: Number of agent: all :: 11 to use: 10\n",
      "[INFO: datasets.py:  400]: Number of action: all :: 22 to use: 19\n",
      "[INFO: datasets.py:  400]: Number of loc: all :: 12 to use: 12\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6000 in 2014-06-26-09-31-18_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6000 in 2014-12-10-18-10-50_stereo_centre_02\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 3000 in 2015-02-03-08-45-10_stereo_centre_04\n",
      "[INFO: datasets.py:  494]: number of start frames: 39\n",
      "[INFO: datasets.py:  487]: Frames with Boxes are 0 out of 6001 in 2015-02-06-13-57-16_stereo_centre_01\n",
      "[INFO: datasets.py:  494]: number of start frames: 77\n",
      "Assertion passed: self.__len__() == len(self.labelled_ids) + len(self.unlabelled_ids)\n",
      "[INFO: main.py:  319]: Done Loading Dataset Validation Dataset\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "[INFO: main.py:  338]: ANCHOR_TYPE: RETINA\n",
      "[INFO: main.py:  338]: ARCH: resnet50\n",
      "[INFO: main.py:  338]: BATCH_SIZE: 20\n",
      "[INFO: main.py:  338]: CLASSWISE_NMS: False\n",
      "[INFO: main.py:  338]: CLS_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: COMPUTE_PATHS: False\n",
      "[INFO: main.py:  338]: COMPUTE_TUBES: False\n",
      "[INFO: main.py:  338]: CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: DATASET: road\n",
      "[INFO: main.py:  338]: DATA_ROOT: /root/autodl-tmp/road-dataset-master/\n",
      "[INFO: main.py:  338]: DATETIME_NOW: 2023-10-06 22:22:47.975590\n",
      "[INFO: main.py:  338]: DEBUG_num_iter: 0\n",
      "[INFO: main.py:  338]: EVAL_EPOCHS: [20]\n",
      "[INFO: main.py:  338]: EXP_NAME: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: FBN: True\n",
      "[INFO: main.py:  338]: FREEZE_UPTO: 1\n",
      "[INFO: main.py:  338]: GAMMA: 0.1\n",
      "[INFO: main.py:  338]: GEN_CONF_THRESH: 0.025\n",
      "[INFO: main.py:  338]: GEN_NMS: 0.5\n",
      "[INFO: main.py:  338]: GEN_TOPK: 30\n",
      "[INFO: main.py:  338]: HEAD_LAYERS: 3\n",
      "[INFO: main.py:  338]: IOU_THRESH: 0.5\n",
      "[INFO: main.py:  338]: JOINT_4M_MARGINALS: False\n",
      "[INFO: main.py:  338]: LOGIC: Lukasiewicz\n",
      "[INFO: main.py:  338]: LOG_START: 10\n",
      "[INFO: main.py:  338]: LOG_STEP: 10\n",
      "[INFO: main.py:  338]: LR: 0.00041\n",
      "[INFO: main.py:  338]: MAN_SEED: 42\n",
      "[INFO: main.py:  338]: MAX_EPOCHS: 150\n",
      "[INFO: main.py:  338]: MAX_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MAX_SIZE: 691\n",
      "[INFO: main.py:  338]: MEANS: [0.485, 0.456, 0.406]\n",
      "[INFO: main.py:  338]: MILESTONES: [130, 145]\n",
      "[INFO: main.py:  338]: MIN_SEQ_STEP: 1\n",
      "[INFO: main.py:  338]: MIN_SIZE: 512\n",
      "[INFO: main.py:  338]: MODE: gen_dets\n",
      "[INFO: main.py:  338]: MODEL_PATH: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/resnet50RCGRU.pth\n",
      "[INFO: main.py:  338]: MODEL_TYPE: RCGRU\n",
      "[INFO: main.py:  338]: MOMENTUM: 0.9\n",
      "[INFO: main.py:  338]: MULTI_GPUS: False\n",
      "[INFO: main.py:  338]: NEGTIVE_THRESHOLD: 0.4\n",
      "[INFO: main.py:  338]: NMS_THRESH: 0.5\n",
      "[INFO: main.py:  338]: NUM_FEATURE_MAPS: 5\n",
      "[INFO: main.py:  338]: NUM_WORKERS: 8\n",
      "[INFO: main.py:  338]: OPTIM: ADAMW\n",
      "[INFO: main.py:  338]: PATHS_COST_TYPE: score\n",
      "[INFO: main.py:  338]: PATHS_IOUTH: 0.5\n",
      "[INFO: main.py:  338]: PATHS_JUMP_GAP: 4\n",
      "[INFO: main.py:  338]: PATHS_MINSCORE: 0.1\n",
      "[INFO: main.py:  338]: PATHS_MIN_LEN: 6\n",
      "[INFO: main.py:  338]: POSTIVE_THRESHOLD: 0.5\n",
      "[INFO: main.py:  338]: REG_HEAD_TIME_SIZE: 3\n",
      "[INFO: main.py:  338]: RESUME: 20\n",
      "[INFO: main.py:  338]: SAVE_ROOT: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: SEQ_LEN: 80\n",
      "[INFO: main.py:  338]: STDS: [0.229, 0.224, 0.225]\n",
      "[INFO: main.py:  338]: SUBSETS: ['test']\n",
      "[INFO: main.py:  338]: TASK: 2\n",
      "[INFO: main.py:  338]: TENSORBOARD: 1\n",
      "[INFO: main.py:  338]: TEST_BATCH_SIZE: 1\n",
      "[INFO: main.py:  338]: TEST_SEQ_LEN: 80\n",
      "[INFO: main.py:  338]: TEST_SUBSETS: ['test']\n",
      "[INFO: main.py:  338]: TOPK: 20\n",
      "[INFO: main.py:  338]: TRAIN_SUBSETS: ['train_1']\n",
      "[INFO: main.py:  338]: TRIM_METHOD: none\n",
      "[INFO: main.py:  338]: TUBES_ALPHA: 0\n",
      "[INFO: main.py:  338]: TUBES_EVAL_THRESHS: [0.2, 0.5]\n",
      "[INFO: main.py:  338]: TUBES_MINLEN: 5\n",
      "[INFO: main.py:  338]: TUBES_TOPK: 10\n",
      "[INFO: main.py:  338]: VAL_STEP: 10\n",
      "[INFO: main.py:  338]: VAL_SUBSETS: ['val_1']\n",
      "[INFO: main.py:  338]: WARMUP_LR: 0.0001\n",
      "[INFO: main.py:  338]: WEIGHT_DECAY: 0.005\n",
      "[INFO: main.py:  338]: agentness_th: 0.125\n",
      "[INFO: main.py:  338]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking']]\n",
      "[INFO: main.py:  338]: ar: 9\n",
      "[INFO: main.py:  338]: exp_name: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\n",
      "[INFO: main.py:  338]: head_size: 256\n",
      "[INFO: main.py:  338]: hostname: autodl-container-d2c311873c-5a3dc589\n",
      "[INFO: main.py:  338]: label_types: ['agent_ness', 'agent', 'action', 'loc']\n",
      "[INFO: main.py:  338]: labelled_videos: ['2014-06-25-16-45-34_stereo_centre_02', '2014-07-14-14-49-50_stereo_centre_01', '2014-07-14-15-42-55_stereo_centre_03', '2014-08-08-13-15-11_stereo_centre_01', '2014-08-11-10-59-18_stereo_centre_02', '2014-11-14-16-34-33_stereo_centre_06', '2014-11-18-13-20-12_stereo_centre_05', '2014-11-21-16-07-03_stereo_centre_01', '2014-12-09-13-21-02_stereo_centre_01', '2015-02-03-08-45-10_stereo_centre_02', '2015-02-03-19-43-11_stereo_centre_04', '2015-02-06-13-57-16_stereo_centre_02', '2015-02-13-09-16-26_stereo_centre_05', '2015-02-24-12-32-19_stereo_centre_04', '2015-03-03-11-31-36_stereo_centre_01']\n",
      "[INFO: main.py:  338]: log_dir: logs//root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x//\n",
      "[INFO: main.py:  338]: log_ulb_gt_separately: False\n",
      "[INFO: main.py:  338]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]\n",
      "[INFO: main.py:  338]: model_init: kinetics\n",
      "[INFO: main.py:  338]: model_perms: [3, 4, 6, 3]\n",
      "[INFO: main.py:  338]: model_subtype: RCGRU\n",
      "[INFO: main.py:  338]: non_local_inds: [[], [], [], []]\n",
      "[INFO: main.py:  338]: num_classes: 42\n",
      "[INFO: main.py:  338]: num_classes_list: [1, 10, 19, 12]\n",
      "[INFO: main.py:  338]: num_label_types: 4\n",
      "[INFO: main.py:  338]: pretrained_model_path: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\n",
      "[INFO: main.py:  338]: pretrained_model_path2: /root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\n",
      "[INFO: main.py:  338]: req_loss_weight: 8.0\n",
      "[INFO: main.py:  338]: skip_beggning: 2\n",
      "[INFO: main.py:  338]: skip_ending: 0\n",
      "[INFO: main.py:  338]: unlabelled_proportion: 0.0\n",
      "[INFO: main.py:  338]: user: root\n",
      "[INFO: gen_dets.py:   30]: Testing at 20\n",
      "[INFO: gen_dets.py:   33]: detection saving dir is :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/detections-20-80-50_test/\n",
      "[INFO: gen_dets.py:   45]: Detection saving pkl file path  :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-20-80-50_test.pkl\n",
      "[INFO: gen_dets.py:   46]: Detection saving zip file path  :: /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-20-80-50_test.zip\n",
      "[INFO: gen_dets.py:   74]: Finished loading model 20 !\n",
      "[INFO: gen_dets.py:  182]: Forward Time 6.741\n",
      "[INFO: gen_dets.py:  250]: im_detect: 1/270 time taken 16.339\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 3.125\n",
      "[INFO: gen_dets.py:  182]: Forward Time 3.233\n",
      "[INFO: gen_dets.py:  250]: im_detect: 51/270 time taken 256.429\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 1.340\n",
      "[INFO: gen_dets.py:  182]: Forward Time 3.226\n",
      "[INFO: gen_dets.py:  250]: im_detect: 101/270 time taken 295.703\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 3.506\n",
      "[INFO: gen_dets.py:  182]: Forward Time 3.217\n",
      "[INFO: gen_dets.py:  250]: im_detect: 151/270 time taken 273.827\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 2.281\n",
      "[INFO: gen_dets.py:  182]: Forward Time 3.220\n",
      "[INFO: gen_dets.py:  250]: im_detect: 201/270 time taken 278.717\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 3.556\n",
      "[INFO: gen_dets.py:  182]: Forward Time 3.221\n",
      "[INFO: gen_dets.py:  250]: im_detect: 251/270 time taken 354.219\n",
      "[INFO: gen_dets.py:  256]: NMS stuff Time 3.135\n",
      "[INFO: gen_dets.py:   89]: Complete set time 1590.61\n",
      "\n",
      " Pickle dets file /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-20-80-50_test.pkl\n",
      "\n",
      " Zip dets file /root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-20-80-50_test.zip\n"
     ]
    }
   ],
   "source": [
    "# Example (b): training with Lukasiewicz t-norm-based loss.\n",
    "\n",
    "DATA_ROOT=\"../\" # should contain a directory named road\n",
    "EXPDIR=\"../experiments/\" # the directory where the experiments will be stored; recommended for it to be located outside the repository, e.g. ../experiments/\n",
    "MODEL_PATH=\"../kinetics-pt/\" # should contain the .pth checkpoint for the specified args.MODEL_TYPE (e.g. resnet50RCGRU.pth if args.MODEL_TYPE==\"RCGRU\")\n",
    "\n",
    "TASK=2\n",
    "EXP_ID=\"task2\"\n",
    "LOGIC=\"Lukasiewicz\"\n",
    "EXP_NAME=\"../experiments/task2/road/logic-ssl_cache_Lukasiewicz_10.0/resnet50RCGRU512-Pkinetics-b4s8x1x1-roadt1-h3x3x3-05-01-01-01-01x/\"\n",
    "! python main.py --RESUME=20 --TASK=2 --MODEL_PATH=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/kinetics-pt/\" --EXPDIR=\"/root/autodl-tmp/road-dataset-master/experiments/\" --DATA_ROOT=\"/root/autodl-tmp/road-dataset-master/\" --TEST_SUBSETS=test --EVAL_EPOCHS=20 --pretrained_model_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/swin-large-p244-w877_in22k-pre_16xb8-amp-32x2x1-30e_kinetics700-rgb_20220930-f8d74db7.pth\" --pretrained_model_path2=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/pretrainmodel/pretrained_weights_task2.pth\"  --SAVE_ROOT=\"/root/autodl-tmp/road-dataset-master/SAVE2/\" --EXP_NAME=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/\" --MODE=\"gen_dets\" --LOGIC=\"Lukasiewicz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ! python post_processing.py --file_path=\"/root/autodl-tmp/road-dataset-master/SAVE/road/logic-ssl_cache_Lukasiewicz_8.0/resnet50RCGRU512-Pkinetics-b20s8x1x1-roadt1t2t3-h3x3x3-10-03-17-52-36x/pred_detections-21-80-50_test.pkl\" --requirements_path=\"/root/autodl-tmp/road-dataset-master/ROAD-R-2023-Challenge-main_me/constraints/WDIMACS_requirements.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing the predictions\n",
    "\n",
    "To postprocess the predictions, and thus guarantee that the requirements are satisfied, use the output `.pkl` file (from `EXP_NAME`) as input to the postprocessing module, based on the [MaxHS solver](https://github.com/fbacchus/MaxHS/tree/master), from `postprocessing/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
